{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05_CMAB_movielens_linear_tf.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPqI8D8Tl3vxivPe9HxAXyN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "17e2398238ce40169fdd423aff450100": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_aa5fdd81e02e43b693b5653d3e2d6e1d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_47e05f3e7a734c1d93b6a619dd3fb1ef",
              "IPY_MODEL_5e8e893643f7404b9036e3fa7f608c8a"
            ]
          }
        },
        "aa5fdd81e02e43b693b5653d3e2d6e1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "47e05f3e7a734c1d93b6a619dd3fb1ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_06775c0bf7d34ad9bf804b53307c8254",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 150,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 150,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_51acde6b7335451aa598e02b0f65b51c"
          }
        },
        "5e8e893643f7404b9036e3fa7f608c8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_687fb42d4b07486aab0112cea32a8159",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 150/150 [01:44&lt;00:00,  1.44it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cf2f86b42c8a45b5b7d3c0cdf4cd0393"
          }
        },
        "06775c0bf7d34ad9bf804b53307c8254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "51acde6b7335451aa598e02b0f65b51c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "687fb42d4b07486aab0112cea32a8159": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cf2f86b42c8a45b5b7d3c0cdf4cd0393": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eb18452a0b9b4b6f9a2e0acca2107348": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9605961d16894b37ae1b9a332df3ba04",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_846642e0dc2646a49b75f92e102154e6",
              "IPY_MODEL_4168a56c307f4906bb14f6f6c7ec5a4e"
            ]
          }
        },
        "9605961d16894b37ae1b9a332df3ba04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "846642e0dc2646a49b75f92e102154e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_137cb3364be448ccbe1919d6f6905c21",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 150,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 150,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_22c27a5634aa4a65aa84f216a5537714"
          }
        },
        "4168a56c307f4906bb14f6f6c7ec5a4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e912e41fb5b04da8b230b2217c34bc0b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 150/150 [01:43&lt;00:00,  1.45it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2a14914eb9ce440c96af0d45b331fab5"
          }
        },
        "137cb3364be448ccbe1919d6f6905c21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "22c27a5634aa4a65aa84f216a5537714": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e912e41fb5b04da8b230b2217c34bc0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2a14914eb9ce440c96af0d45b331fab5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pstanisl/mlprague-2021/blob/main/05_CMAB_movielens_linear_tf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ku9blLrybt_E"
      },
      "source": [
        "# Linear Contextual Multi-Armed Bandits \n",
        "\n",
        "From now we will use [TensorFlow Agents](https://www.tensorflow.org/agents), so so it's probably appropriate to say something about this library. Agents is a library for reinforcement learning in TensorFlow.  \n",
        "\n",
        "> TF-Agents makes designing, implementing, and testing new RL algorithms easier by providing well-tested modular components that can be modified and extended. It enables fast code iteration with good test integration and benchmarking.\n",
        "\n",
        "It provides API for creating all aspects necessary for reinforcement learning with Tensorflow, example of API can be seen below.\n",
        "\n",
        "```python\n",
        "import tensorflow as tf\n",
        "from tf_agents.networks import q_network\n",
        "from tf_agents.agents.dqn import dqn_agent\n",
        "\n",
        "q_net = q_network.QNetwork(\n",
        "  train_env.observation_spec(),\n",
        "  train_env.action_spec(),\n",
        "  fc_layer_params=(100,))\n",
        "\n",
        "agent = dqn_agent.DqnAgent(\n",
        "  train_env.time_step_spec(),\n",
        "  train_env.action_spec(),\n",
        "  q_network=q_net,\n",
        "  optimizer=optimizer,\n",
        "  td_errors_loss_fn=common.element_wise_squared_loss,\n",
        "  train_step_counter=tf.Variable(0))\n",
        "\n",
        "agent.initialize()\n",
        "```\n",
        "\n",
        "As Multi-Armed Bandits can be seen as a special case of RL, TF-Agents contains also building blocks for MAB, especially for Contextual Multi-Armed Bandits (CMAB). ☺️\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6fNTjpnu6eS"
      },
      "source": [
        "#### Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbVPxLuUR25T",
        "outputId": "1e393170-c611-4110-9f87-99a8a8773c33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install tf-agents -q"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10kB 10.5MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 16.4MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 21.5MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 14.3MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51kB 8.4MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61kB 9.6MB/s eta 0:00:01\r\u001b[K     |██                              | 71kB 8.7MB/s eta 0:00:01\r\u001b[K     |██▏                             | 81kB 8.7MB/s eta 0:00:01\r\u001b[K     |██▍                             | 92kB 9.3MB/s eta 0:00:01\r\u001b[K     |██▊                             | 102kB 9.5MB/s eta 0:00:01\r\u001b[K     |███                             | 112kB 9.5MB/s eta 0:00:01\r\u001b[K     |███▎                            | 122kB 9.5MB/s eta 0:00:01\r\u001b[K     |███▌                            | 133kB 9.5MB/s eta 0:00:01\r\u001b[K     |███▉                            | 143kB 9.5MB/s eta 0:00:01\r\u001b[K     |████                            | 153kB 9.5MB/s eta 0:00:01\r\u001b[K     |████▎                           | 163kB 9.5MB/s eta 0:00:01\r\u001b[K     |████▋                           | 174kB 9.5MB/s eta 0:00:01\r\u001b[K     |████▉                           | 184kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 194kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 204kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 215kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████                          | 225kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 235kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 245kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 256kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████                         | 266kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 276kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 286kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 296kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████                        | 307kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 317kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 327kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████                       | 337kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 348kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 358kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 368kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████                      | 378kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 389kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 399kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 409kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 419kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 430kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 440kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 450kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 460kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 471kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 481kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 491kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 501kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 512kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 522kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 532kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 542kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 552kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 563kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 573kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 583kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 593kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████                | 604kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 614kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 624kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 634kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 645kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 655kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 665kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 675kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 686kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 696kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 706kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 716kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 727kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 737kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 747kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 757kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 768kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 778kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 788kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 798kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 808kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 819kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 829kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 839kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 849kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 860kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 870kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 880kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 890kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 901kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 911kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 921kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 931kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 942kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 952kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 962kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 972kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 983kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 993kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.0MB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.0MB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.0MB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.0MB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.0MB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.1MB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1MB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.1MB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.1MB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.1MB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1MB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.1MB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.1MB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1MB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1MB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.2MB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.2MB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2MB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2MB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.2MB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2MB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2MB 9.5MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2MMqktAoX5e",
        "outputId": "f4212191-f06c-493a-888f-56e6c0b7133d"
      },
      "source": [
        "!rm -f ./utils.py\n",
        "!wget --no-check-certificate --no-cache --no-cookies \\\n",
        "    https://raw.githubusercontent.com/pstanisl/mlprague-2021/main/utils.py \\\n",
        "    -O ./utils.py"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-25 15:03:50--  https://raw.githubusercontent.com/pstanisl/mlprague-2021/main/utils.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4245 (4.1K) [text/plain]\n",
            "Saving to: ‘./utils.py’\n",
            "\n",
            "./utils.py          100%[===================>]   4.15K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-02-25 15:03:50 (48.7 MB/s) - ‘./utils.py’ saved [4245/4245]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02ZZepbLdTS7"
      },
      "source": [
        "#### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUEquHXHRwwB"
      },
      "source": [
        "import functools\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf  # pylint: disable=g-explicit-tensorflow-version-import\n",
        "import tensorflow_probability as tfp\n",
        "import zipfile\n",
        "\n",
        "from tqdm.notebook import trange\n",
        "from typing import Optional, Sequence, Text, Tuple\n",
        "\n",
        "from tf_agents.agents import data_converter\n",
        "from tf_agents.agents import tf_agent\n",
        "from tf_agents.bandits.agents import linear_bandit_agent as lin_agent\n",
        "from tf_agents.bandits.agents import utils as bandit_utils\n",
        "from tf_agents.bandits.environments import environment_utilities\n",
        "from tf_agents.bandits.environments import bandit_py_environment\n",
        "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
        "from tf_agents.bandits.policies import linalg\n",
        "from tf_agents.bandits.policies import linear_bandit_policy\n",
        "from tf_agents.bandits.policies import policy_utilities\n",
        "from tf_agents.drivers import dynamic_step_driver\n",
        "from tf_agents.environments import tf_py_environment\n",
        "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
        "from tf_agents.policies import tf_policy\n",
        "from tf_agents.specs import array_spec\n",
        "from tf_agents.trajectories import policy_step\n",
        "from tf_agents.trajectories import time_step as ts\n",
        "from tf_agents.typing import types\n",
        "\n",
        "from utils import load_movielens_data, plot_regret"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b47tWwUVdgbV"
      },
      "source": [
        "#### Downloading the [MovieLens](https://grouplens.org/datasets/movielens/) (100K) dataset.\n",
        "\n",
        "**Dataset info**\n",
        "\n",
        "MovieLens data sets were collected by the GroupLens Research Project\n",
        "at the University of Minnesota.\n",
        "\n",
        "This data set consists of:\n",
        "* 100,000 ratings (1-5) from 943 users on 1682 movies.\n",
        "* Each user has rated at least 20 movies.\n",
        "* Simple demographic info for the users (age, gender, occupation, zip)\n",
        "\n",
        "The data was collected through the MovieLens web site\n",
        "(movielens.umn.edu) during the seven-month period from September 19th,\n",
        "1997 through April 22nd, 1998. This data has been cleaned up - users\n",
        "who had less than 20 ratings or did not have complete demographic\n",
        "information were removed from this data set. Detailed descriptions of\n",
        "the data file can be found at the end of this file.\n",
        "\n",
        "Neither the University of Minnesota nor any of the researchers\n",
        "involved can guarantee the correctness of the data, its suitability\n",
        "for any particular purpose, or the validity of results based on the\n",
        "use of the data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8_xdGprnyqb",
        "outputId": "c3090781-0703-448c-b7ab-f88df83feed3"
      },
      "source": [
        "print(\"Downloading movielens data...\")\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    http://files.grouplens.org/datasets/movielens/ml-100k.zip \\\n",
        "    -O ./movielens.zip\n",
        "\n",
        "zip_ref = zipfile.ZipFile('movielens.zip', \"r\")\n",
        "zip_ref.extractall()\n",
        "\n",
        "print(\"Done. Dataset contains:\")\n",
        "print(zip_ref.read('ml-100k/u.info').decode())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading movielens data...\n",
            "--2021-02-25 15:03:53--  http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4924029 (4.7M) [application/zip]\n",
            "Saving to: ‘./movielens.zip’\n",
            "\n",
            "./movielens.zip     100%[===================>]   4.70M  10.7MB/s    in 0.4s    \n",
            "\n",
            "2021-02-25 15:03:54 (10.7 MB/s) - ‘./movielens.zip’ saved [4924029/4924029]\n",
            "\n",
            "Done. Dataset contains:\n",
            "943 users\n",
            "1682 items\n",
            "100000 ratings\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBsEus-bdkRM"
      },
      "source": [
        "#### Parameters -- Feel Free to Play Around"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2Tf9d1NcbF9"
      },
      "source": [
        "RANK_K = 20 # @param {type:\"integer\"}\n",
        "NUM_ACTIONS = 20 # @param {type:\"integer\"}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvFAsPqLlmKQ"
      },
      "source": [
        "## Environment\n",
        "\n",
        "Implementation of the environment uses **MovieLens 100K dataset**. As described above, the dataset contains 100000 ratings from 943 users and 1682 movies. The environment can consider only the first $n$ of the dataset's movies. It can be set-up by `num_actions`. The number of \"known\" movies for the environment is equal to actions/arms.\n",
        "\n",
        "> Users without a rating (after selecting first $n$ movies) are removed from the environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW6QuzcKX8gq"
      },
      "source": [
        "class MovieLensPyEnvironment(bandit_py_environment.BanditPyEnvironment):\n",
        "  \"\"\"Implements the MovieLens Bandit environment.\n",
        "  This environment implements the MovieLens 100K dataset, available at:\n",
        "  https://www.kaggle.com/prajitdatta/movielens-100k-dataset\n",
        "  This dataset contains 100K ratings from 943 users on 1682 items.\n",
        "  This csv list of:\n",
        "  user id | item id | rating | timestamp.\n",
        "  This environment computes a low-rank matrix factorization (using SVD) of the\n",
        "  data matrix A, such that: A ~= U * V.\n",
        "  The reward of recommending item `j` to user `i` is provided as A_{ij}.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               data_dir: Text,\n",
        "               rank_k: int,\n",
        "               batch_size: int = 1,\n",
        "               num_movies: int = 20,\n",
        "               name: Optional[Text] = 'movielens'):\n",
        "    \"\"\"Initializes the MovieLens Bandit environment.\n",
        "    Args:\n",
        "      data_dir: (string) Directory where the data lies (in text form).\n",
        "      rank_k : (int) Which rank to use in the matrix factorization.\n",
        "      batch_size: (int) Number of observations generated per call.\n",
        "      num_movies: (int) Only the first `num_movies` movies will be used by the\n",
        "        environment. The rest is cut out from the data.\n",
        "      name: The name of this environment instance.\n",
        "    \"\"\"\n",
        "    self._num_actions = num_movies\n",
        "    self._batch_size = batch_size\n",
        "    self._context_dim = rank_k\n",
        "\n",
        "    # Compute the matrix factorization.\n",
        "    #self._data_matrix = dataset_utilities.load_movielens_data(data_dir)\n",
        "    self._data_matrix = load_movielens_data(data_dir)\n",
        "    # Keep only the first items.\n",
        "    self._data_matrix = self._data_matrix[:, :num_movies]\n",
        "    # Filter the users with no iterm rated.\n",
        "    nonzero_users = list(np.nonzero(np.sum(self._data_matrix, axis=1) > 0.0)[0])\n",
        "    self._data_matrix = self._data_matrix[nonzero_users, :]\n",
        "    self._effective_num_users = len(nonzero_users)\n",
        "\n",
        "    # Compute the SVD.\n",
        "    u, s, vh = np.linalg.svd(self._data_matrix, full_matrices=False)\n",
        "\n",
        "    # Keep only the largest singular values.\n",
        "    self._u_hat = u[:, :rank_k] * np.sqrt(s[:rank_k])\n",
        "    self._v_hat = np.transpose(\n",
        "        np.transpose(vh[:rank_k, :]) * np.sqrt(s[:rank_k]))\n",
        "    self._approx_ratings_matrix = np.matmul(self._u_hat, self._v_hat)\n",
        "\n",
        "    self._current_users = np.zeros(batch_size, dtype=np.int32)\n",
        "    self._previous_users = np.zeros(batch_size, dtype=np.int32)\n",
        "\n",
        "    self._action_spec = array_spec.BoundedArraySpec(\n",
        "        shape=(),\n",
        "        dtype=np.int32,\n",
        "        minimum=0,\n",
        "        maximum=self._num_actions - 1,\n",
        "        name='action')\n",
        "    observation_spec = array_spec.ArraySpec(\n",
        "        shape=(self._context_dim,), dtype=np.float64, name='observation')\n",
        "    self._time_step_spec = ts.time_step_spec(observation_spec)\n",
        "    self._observation = np.zeros((self._batch_size, self._context_dim))\n",
        "\n",
        "    self._optimal_action_table = np.argmax(\n",
        "        self._approx_ratings_matrix, axis=1)\n",
        "    self._optimal_reward_table = np.max(\n",
        "        self._approx_ratings_matrix, axis=1)\n",
        "\n",
        "    super(MovieLensPyEnvironment, self).__init__(\n",
        "        observation_spec, self._action_spec)\n",
        "\n",
        "  @property\n",
        "  def batch_size(self):\n",
        "    return self._batch_size\n",
        "\n",
        "  @property\n",
        "  def batched(self):\n",
        "    return True\n",
        "\n",
        "  def _observe(self):\n",
        "    \"\"\"Returns the u vectors of a random sample of users.\"\"\"\n",
        "    sampled_users = random.sample(\n",
        "        range(self._effective_num_users), self._batch_size)\n",
        "    self._previous_users = self._current_users\n",
        "    self._current_users = sampled_users\n",
        "    batched_observations = self._u_hat[sampled_users]\n",
        "    return batched_observations\n",
        "\n",
        "  def _apply_action(self, action):\n",
        "    \"\"\"Computes the reward for the input actions.\"\"\"\n",
        "    rewards = []\n",
        "    for i, j in zip(self._current_users, action):\n",
        "      rewards.append(self._approx_ratings_matrix[i, j])\n",
        "    return np.array(rewards)\n",
        "\n",
        "  def compute_optimal_action(self):\n",
        "    return self._optimal_action_table[self._previous_users]\n",
        "\n",
        "  def compute_optimal_reward(self):\n",
        "    return self._optimal_reward_table[self._previous_users]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rxo7RipFdrPk"
      },
      "source": [
        "Now we are equipped to initialize our environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWLNxLEiT05z"
      },
      "source": [
        "env = MovieLensPyEnvironment('./ml-100k/u.data', RANK_K, 8, num_movies=NUM_ACTIONS)\n",
        "tf_env = tf_py_environment.TFPyEnvironment(env)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4IcbZr5duJt"
      },
      "source": [
        "Below we can check what this environment produces."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcRZbsaSUCEh",
        "outputId": "d4da2467-566a-4717-91ad-c9400fb136d9"
      },
      "source": [
        "print('Observation spec:', tf_env.observation_spec())\n",
        "print('An observation: ', tf_env.reset().observation.numpy())\n",
        "\n",
        "action = tf.zeros(8, dtype=tf.int32)\n",
        "time_step = tf_env.step(action)\n",
        "\n",
        "print()\n",
        "print(f'Action={action.numpy()} (optimal={tf_env.compute_optimal_action()})')\n",
        "print(f'Reward={time_step.reward.numpy()} (optimal={tf_env.compute_optimal_reward()})')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Observation spec: TensorSpec(shape=(20,), dtype=tf.float64, name='observation')\n",
            "An observation:  [[-2.22181463e-01 -1.24641478e-03  4.12840311e-02 -5.47598410e-01\n",
            "   9.37761750e-02  1.26460932e-01 -4.06877115e-01 -3.93566150e-02\n",
            "   3.14424829e-01 -1.10436344e-01  3.21215436e-01  4.54434325e-03\n",
            "   1.63871605e-01 -1.14554336e-01  1.72397948e-02  4.97991173e-02\n",
            "  -9.10440256e-03 -3.57498130e-02  6.26455876e-02 -1.55330628e-02]\n",
            " [-2.26694730e-02 -4.71847233e-02 -9.13471845e-03  2.28269527e-03\n",
            "  -2.51510568e-02  1.06734615e-02  2.45667358e-02 -6.47878631e-02\n",
            "  -8.18444847e-02 -8.24814823e-02  2.39514616e-02  1.78902722e-02\n",
            "  -3.97713662e-04 -1.39665440e-02  2.79896173e-03  1.06359534e-02\n",
            "   3.36938465e-03  5.60817880e-03 -4.94006002e-03 -3.32156444e-04]\n",
            " [-4.42468772e-01  1.25450730e-01 -4.06478386e-01 -1.37284730e-01\n",
            "   4.63145563e-01 -4.31252175e-01 -4.89546457e-01  1.46261240e-01\n",
            "  -1.68702739e-01  9.79670188e-02  1.24800023e-01 -4.92851329e-03\n",
            "  -4.45261812e-02  1.61785963e-02 -2.31255660e-02  2.40602218e-02\n",
            "   1.20978336e-02  1.98056943e-02 -3.40647774e-02 -3.40404881e-02]\n",
            " [-7.97303374e-01 -4.90218721e-01  5.18139654e-01 -5.99526970e-03\n",
            "   3.40123015e-02 -2.70430322e-01 -4.37221704e-01 -1.47619405e-01\n",
            "   4.07060245e-01 -3.76258714e-01  3.53589194e-01  2.29096365e-01\n",
            "  -6.22748464e-02  3.43793407e-03 -1.30052965e-01 -3.76768901e-01\n",
            "  -1.44424742e-01 -1.61033436e-01 -8.62367471e-03  1.62514397e-02]\n",
            " [-2.19717028e-01 -2.84603448e-01  3.22634086e-02  6.95289676e-03\n",
            "   5.18466352e-02  6.79780908e-02 -1.06614441e-01  1.92119779e-01\n",
            "   1.34591686e-01  2.29398636e-01 -3.08265334e-02  1.55469069e-01\n",
            "  -2.76105759e-02 -4.95766656e-02 -6.26926036e-02 -3.55722321e-02\n",
            "   3.16996676e-02  3.73970510e-03 -1.49563744e-03  8.27375156e-03]\n",
            " [-5.44369834e-01  4.94756961e-01  2.18684050e-01  3.25126381e-01\n",
            "  -2.80930349e-01  2.05062881e-01  3.93025170e-01  4.59825283e-01\n",
            "  -2.24678215e-01  2.12229972e-01  5.82941127e-02  9.16136409e-02\n",
            "   1.86018198e-01  1.00326715e-01  5.28667900e-02 -2.02549974e-02\n",
            "  -1.04640618e-01 -2.05235836e-02  5.36984989e-02  2.05960474e-02]\n",
            " [-6.41683613e-01 -1.27627658e-01  6.33057061e-03 -4.53485656e-01\n",
            "   3.67057761e-01  2.84065732e-01  3.47749132e-01 -7.88164528e-01\n",
            "  -2.81599232e-01  1.37306198e-01  1.27994878e-01  6.19768193e-02\n",
            "  -2.36895868e-01  5.08071828e-01 -1.23796714e-01 -5.88027258e-01\n",
            "  -4.56167446e-01  3.74768104e-01  1.51166347e-01  1.45773453e-02]\n",
            " [-7.46704463e-01  1.32637072e-03  3.46098592e-01  3.36502836e-01\n",
            "  -2.46265519e-01  4.03439027e-01  5.34692195e-01 -9.04389580e-02\n",
            "   1.71837854e-01 -1.11616780e-01  4.22371745e-01  1.10410102e-01\n",
            "   1.34562325e-02  6.78456190e-02  5.06552325e-01 -5.19504402e-02\n",
            "   1.35721223e-01 -1.02777620e-01  3.19892443e-02  2.55880960e-02]]\n",
            "\n",
            "Action=[0 0 0 0 0 0 0 0] (optimal=[ 6 10  0  8 11 14  3 11])\n",
            "Reward=[1.2621145e-14 1.2087450e-15 5.0000000e+00 3.9758297e-14 1.1269491e-14\n",
            " 4.0000000e+00 4.0000000e+00 3.0000000e+00] (optimal=[5. 1. 5. 5. 3. 5. 5. 5.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTjTE8ThV85o"
      },
      "source": [
        "## Policy - LinerUCB\n",
        "\n",
        "As we leant in UCB example, the Upper Confidence Bounds (UCB) algorithm measures potential by an upper confidence bound of the reward value, $\\hat{U}_{t}(a)$, so that the true value is below with bound $Q(a) \\leq \\hat{Q}_t(a) + \\hat{U}_t(a)$ with high probability. The upper bound $\\hat{U}_t(a)$ is a function of $N_t(a)$; a larger number of trials $N_t(a)$ should give us a smaller bound $\\hat{U}_t(a)$, see picture below.\n",
        "\n",
        "<center>\n",
        "  <img src=\"https://miro.medium.com/max/4800/1*p_4mvZ6r6ddbShd7tOT0sw.png\" alt=\"source: https://towardsdatascience.com/recommender-systems-using-linucb-a-contextual-multi-armed-bandit-approach-35a6f0eb6c4\" width=\"600\"/>\n",
        "</center>\n",
        "\n",
        "<!--![](https://miro.medium.com/max/4800/1*p_4mvZ6r6ddbShd7tOT0sw.png \"source: https://towardsdatascience.com/recommender-systems-using-linucb-a-contextual-multi-armed-bandit-approach-35a6f0eb6c4\")-->\n",
        "\n",
        "For contextual bandits UCB, the expected payoff of an action is assumed to be linear in its d-dimensional feature vector $X$ with some unknown coefficient vector $\\theta$.\n",
        "\n",
        "$$\n",
        "E\\left[r_{t,a}|x_{t,a}\\right] = x^{T}_{t,a}\\theta^{\\ast}_{a}\n",
        "$$\n",
        "\n",
        "An upper confidence bound has to be calculated for each action for the algorithm to be able to choose an arm at every trial. The strategy for choosing the action at every trial $t$ is formalised as\n",
        "\n",
        "$$\n",
        "a_{t} \\stackrel{def}{=} argmax\\left(x^{T}_{t,a}\\hat{\\theta}_{a} + \\alpha \\sqrt{x^{T}_{t,a} A^{-1} x_{t,a}} \\right),\n",
        "$$\n",
        "\n",
        "where $\\hat{\\theta} = A^{-1}b$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10eDwxGDV-n6"
      },
      "source": [
        "class LinearUCBPolicy(linear_bandit_policy.LinearBanditPolicy):\n",
        "  \"\"\"LinearUCB policy is simplified version of LinearBanditPolicy from tf_agente.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               action_spec: types.BoundedTensorSpec,\n",
        "               variable_collection: tf.Module,\n",
        "               time_step_spec: Optional[types.TimeStep] = None,\n",
        "               alpha: float = 1.0,\n",
        "               tikhonov_weight: float = 1.0,\n",
        "               name: Optional[Text] = None):\n",
        "    super(LinearUCBPolicy, self).__init__(\n",
        "        action_spec,\n",
        "        cov_matrix=variable_collection.cov_matrix_list,\n",
        "        data_vector=variable_collection.data_vector_list,\n",
        "        num_samples=variable_collection.num_samples_list,\n",
        "        time_step_spec=time_step_spec,\n",
        "        alpha=alpha,\n",
        "        tikhonov_weight=tikhonov_weight,\n",
        "        name=name)\n",
        "\n",
        "  def _distribution(self, time_step, policy_state):\n",
        "    observation = tf.nest.map_structure(lambda o: tf.cast(o, dtype=self._dtype),\n",
        "                                        time_step.observation)\n",
        "    \n",
        "    current_observation = tf.reshape(\n",
        "        observation, [-1, self._global_context_dim])\n",
        "\n",
        "    est_rewards = []\n",
        "    confidence_intervals = []\n",
        "\n",
        "    for model_index in range(self._num_actions):\n",
        "      a = self._cov_matrix[model_index]\n",
        "      b = self._data_vector[model_index]\n",
        "      # Compute confidence interval for action(i): x^T*A^-1*x\n",
        "      # 1: A^-1*x -> A^-1x\n",
        "      a_inv_x = linalg.conjugate_gradient_solve(\n",
        "          a + self._tikhonov_weight *\n",
        "          tf.eye(self._overall_context_dim, dtype=self._dtype),\n",
        "          tf.linalg.matrix_transpose(current_observation))\n",
        "      # 2: x^T*A^-1x -> confidence interval of action(i)\n",
        "      ci = tf.reshape(\n",
        "          tf.linalg.tensor_diag_part(tf.matmul(current_observation, a_inv_x)),\n",
        "          [-1, 1])\n",
        "      \n",
        "      confidence_intervals.append(ci)\n",
        "      est_mean_reward = tf.einsum('j,jk->k', b,\n",
        "                                  a_inv_x)\n",
        "      est_rewards.append(est_mean_reward)\n",
        "    # Estimate rewards for every action\n",
        "    optimistic_estimates = [\n",
        "        tf.reshape(mean_reward, [-1, 1]) + self._alpha * tf.sqrt(confidence)\n",
        "        for mean_reward, confidence in zip(est_rewards, confidence_intervals)\n",
        "    ]\n",
        "    # Keeping the batch dimension during the squeeze, even if batch_size == 1.\n",
        "    rewards_for_argmax = tf.squeeze(\n",
        "        tf.stack(optimistic_estimates, axis=-1), axis=[1])\n",
        "    # Choose the best action for every observation in the batch\n",
        "    chosen_actions = tf.argmax(\n",
        "        rewards_for_argmax,\n",
        "        axis=-1,\n",
        "        output_type=tf.nest.flatten(self._action_spec)[0].dtype)\n",
        "\n",
        "    action_distributions = tfp.distributions.Deterministic(loc=chosen_actions)\n",
        "\n",
        "    policy_info = policy_utilities.populate_policy_info(\n",
        "        None, chosen_actions, rewards_for_argmax,\n",
        "        tf.stack(est_rewards, axis=-1), self._emit_policy_info,\n",
        "        False)\n",
        "\n",
        "    return policy_step.PolicyStep(\n",
        "        action_distributions, policy_state, policy_info)\n",
        "    "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uo3YPdpkxYsr"
      },
      "source": [
        "## Agent\n",
        "\n",
        "For contextual bandits UCB, the expected payoff of an action is assumed to be linear in its d-dimensional feature vector $X$ with some unknown coefficient vector $\\theta$.\n",
        "\n",
        "$$\n",
        "E\\left[r_{t,a}|x_{t,a}\\right] = x^{T}_{t,a}\\theta^{\\ast}_{a}\n",
        "$$\n",
        "\n",
        "This model is called disjoint since the parameters are not shared among different actions/arms. To solve for the coefficient vector $\\theta$ in the above equation ridge regression ([Tikhonov regularization](https://en.wikipedia.org/wiki/Tikhonov_regularization)) is applied to the training data. The whole algorithm is described below\n",
        "\n",
        "<center>\n",
        "  <img src=\"https://raw.githubusercontent.com/pstanisl/mlprague-2021/main/img/linucb_algorithm.png\" alt=\"LinUCB algorithm\" width=\"400\"/>\n",
        "</center>\n",
        "\n",
        "<!--![linucb_algorithm.png](https://raw.githubusercontent.com/pstanisl/mlprague-2021/main/img/linucb_algorithm.png =100x)-->\n",
        "\n",
        "> More details about the algorithm can be found in the [A contextual-bandit approach to\n",
        "personalized news article recommendation](https://arxiv.org/pdf/1003.0146.pdf) and [Linear Upper Confidence Bound Algorithm for Contextual Bandit Problem with Piled Rewards](https://khhuang.me/docs/pakdd2016linucbpr.pdf) papers.\n",
        "\n",
        "The LinearAgent with `LinearUCBPolicy` agent implements the identically named Bandit algorithm, which estimates the parameter of the linear reward function while also maintains a confidence ellipsoid around the estimate. The agent chooses the action/arm that has the highest estimated expected reward, assuming that the parameter lies within the confidence ellipsoid."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2zoC7YYVzxj"
      },
      "source": [
        "def sum_reward_weighted_observations(r: types.Tensor,\n",
        "                                     x: types.Tensor) -> types.Tensor:\n",
        "  \"\"\"Calculates an update used by some Bandit algorithms.\n",
        "  Given an observation `x` and corresponding reward `r`, the weigthed\n",
        "  observations vector (denoted `b` here) should be updated as `b = b + r * x`.\n",
        "  This function calculates the sum of weighted rewards for batched\n",
        "  observations `x`.\n",
        "\n",
        "  Args:\n",
        "    r: a `Tensor` of shape [`batch_size`]. This is the rewards of the batched\n",
        "      observations.\n",
        "    x: a `Tensor` of shape [`batch_size`, `context_dim`]. This is the matrix\n",
        "      with the (batched) observations.\n",
        "      \n",
        "  Returns:\n",
        "    The update that needs to be added to `b`. Has the same shape as `b`.\n",
        "    If the observation matrix `x` is empty, a zero vector is returned.\n",
        "  \"\"\"\n",
        "  batch_size = tf.shape(x)[0]\n",
        "\n",
        "  return tf.reduce_sum(tf.reshape(r, [batch_size, 1]) * x, axis=0)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMo6hdUpD6hO"
      },
      "source": [
        "class LinearAgent(lin_agent.LinearBanditAgent):\n",
        "  \"\"\"Simplified implentation of an agent that maintains linear reward \n",
        "  estimates and their uncertainties.\n",
        "  \n",
        "  Original implementation can be found here: http://bit.ly/3kk7v3D\n",
        "  \"\"\"\n",
        "  def __init__(self,\n",
        "              time_step_spec: types.TimeStep,\n",
        "              action_spec: types.BoundedTensorSpec,\n",
        "              policy_class: linear_bandit_policy.LinearBanditPolicy = LinearUCBPolicy,\n",
        "              alpha: float = 1.0,\n",
        "              tikhonov_weight: float = 1.0,\n",
        "              dtype: tf.DType = tf.float32,\n",
        "              name: Optional[Text] = None):\n",
        "\n",
        "    super(LinearAgent, self).__init__(\n",
        "        lin_agent.ExplorationPolicy.linear_ucb_policy,\n",
        "        time_step_spec=time_step_spec,\n",
        "        action_spec=action_spec,\n",
        "        alpha=alpha,\n",
        "        tikhonov_weight=tikhonov_weight,\n",
        "        dtype=dtype,\n",
        "        name=name\n",
        "    )\n",
        "\n",
        "    self._as_trajectory = data_converter.AsTrajectory(\n",
        "      self.data_context, sequence_length=None)\n",
        "\n",
        "    self._policy = self._policy = policy_class(\n",
        "        action_spec=action_spec,\n",
        "        variable_collection=self._variable_collection,\n",
        "        time_step_spec=time_step_spec,\n",
        "        alpha=alpha,\n",
        "        tikhonov_weight=tikhonov_weight\n",
        "    )\n",
        "  \n",
        "  def _train(self, experience, weights=None):\n",
        "    \"\"\"Updates the policy based on the data in `experience`.\n",
        "    Note that `experience` should only contain data points that this agent has\n",
        "    not previously seen. If `experience` comes from a replay buffer, this buffer\n",
        "    should be cleared between each call to `train`.\n",
        "    Args:\n",
        "      experience: A batch of experience data in the form of a `Trajectory`.\n",
        "      weights: Unused.\n",
        "    Returns:\n",
        "        A `LossInfo` containing the loss *before* the training step is taken.\n",
        "        In most cases, if `weights` is provided, the entries of this tuple will\n",
        "        have been calculated with the weights.  Note that each Agent chooses\n",
        "        its own method of applying weights.\n",
        "    \"\"\"\n",
        "    experience = self._as_trajectory(experience)\n",
        "\n",
        "    del weights  # unused\n",
        "\n",
        "    reward, action, observation, batch_size = self._process_experience(\n",
        "        experience)\n",
        "    \n",
        "    for k in range(self._num_models):\n",
        "      # Create identity matrix used as a mask\n",
        "      diag_mask = tf.linalg.tensor_diag(\n",
        "          tf.cast(tf.equal(action, k), self._dtype))\n",
        "      # Get an observation for the action from the observation\n",
        "      observations_for_arm = tf.matmul(diag_mask, observation)\n",
        "      \n",
        "      rewards_for_arm = tf.matmul(diag_mask, tf.reshape(reward, [-1, 1]))\n",
        "\n",
        "      num_samples_for_arm_current = tf.reduce_sum(diag_mask)\n",
        "      \n",
        "      tf.compat.v1.assign_add(self._num_samples_list[k],\n",
        "                              num_samples_for_arm_current)\n",
        "      num_samples_for_arm_total = self._num_samples_list[k].read_value()\n",
        "\n",
        "      # Update the covariance matrix `a` and the weighted sum of rewards `b`\n",
        "      # using a forgetting factor `gamma`.\n",
        "      x = observations_for_arm\n",
        "      r = rewards_for_arm\n",
        "      a_prev = self._cov_matrix_list[k]\n",
        "      b_prev = self._data_vector_list[k]\n",
        "\n",
        "      a_new = self._gamma * a_prev + tf.matmul(x, x, transpose_a=True)\n",
        "      b_new = self._gamma * b_prev + sum_reward_weighted_observations(r, x)\n",
        "      # Update real variables\n",
        "      tf.compat.v1.assign(self._cov_matrix_list[k], a_new)\n",
        "      tf.compat.v1.assign(self._data_vector_list[k], b_new)\n",
        "\n",
        "    loss = -1. * tf.reduce_sum(reward)\n",
        "    self.compute_summaries(loss)\n",
        "\n",
        "    self._train_step_counter.assign_add(batch_size)\n",
        "\n",
        "    return tf_agent.LossInfo(loss=(loss), extra=())"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Huc03djLkNyt"
      },
      "source": [
        "Helper function for creating an instance of the `LinearAgent` with a linear policy like our `LinearUCBPolicy`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkJm2_WpgfaL"
      },
      "source": [
        "def get_agent(\n",
        "    environment, \n",
        "    policy_class: linear_bandit_policy.LinearBanditPolicy = LinearUCBPolicy,\n",
        "    tikhonov_weight: float = 0.001, \n",
        "    alpha: float = 10.0\n",
        "):  \n",
        "  return LinearAgent(\n",
        "    time_step_spec=environment.time_step_spec(),\n",
        "    action_spec=environment.action_spec(),\n",
        "    policy_class=policy_class,\n",
        "    tikhonov_weight=tikhonov_weight,\n",
        "    alpha=alpha,\n",
        "    dtype=tf.float32\n",
        "  )"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bG8LVv2rW1sK"
      },
      "source": [
        "agent = get_agent(\n",
        "    tf_env, policy_class=LinearUCBPolicy, tikhonov_weight=0.001, alpha=10.0)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nE2kDQ2kcSo"
      },
      "source": [
        "Let have a look at the data specification in the agent. The `training_data_spec` attribute of the agent specifies what elements and structure the training data should have. The `training_data_spec.observation` specificate the structure of the context vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPg7h-hIlTnx",
        "outputId": "e472970b-768e-4746-a75c-a3e12efb9871"
      },
      "source": [
        "print('training data spec: ', agent.training_data_spec)\n",
        "print('observation spec in training: ', agent.training_data_spec.observation)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training data spec:  Trajectory(step_type=TensorSpec(shape=(), dtype=tf.int32, name='step_type'), observation=TensorSpec(shape=(20,), dtype=tf.float64, name='observation'), action=BoundedTensorSpec(shape=(), dtype=tf.int32, name='action', minimum=array(0, dtype=int32), maximum=array(19, dtype=int32)), policy_info=PolicyInfo(log_probability=(), predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=()), next_step_type=TensorSpec(shape=(), dtype=tf.int32, name='step_type'), reward=TensorSpec(shape=(), dtype=tf.float32, name='reward'), discount=BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)))\n",
            "observation spec in training:  TensorSpec(shape=(20,), dtype=tf.float64, name='observation')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDjYCtBUl2j4"
      },
      "source": [
        "## Training\n",
        "\n",
        "Now we put together all the components that we introduced above: the environment, the policy, and the agent. We run the policy on the environment and output training data with the help of a driver, and train the agent on the data.\n",
        "\n",
        "#### Metrics\n",
        "\n",
        "Important of the training are metrics. If you read some materials you can find, that bandits' most important metric is regret, calculated as the difference between the reward collected by the agent and the expected reward of an oracle policy that has access to the reward functions of the environment. The [RegretMetric](https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/metrics/tf_metrics.py) thus needs a `baseline_reward_fn` function that calculates the best achievable expected reward given an observation. In our example, the optimal reward is computed in the `MovieLensPyEnvironment.compute_optimal_reward` from the approximation of the rating.\n",
        "\n",
        "> In reality, we usually do not have access to an oracle policy, so the regret is hard to get. Thus, the cumulative reward or other metric is often used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTmTQNtQpk_a"
      },
      "source": [
        "def get_metrics(environment):\n",
        "  optimal_reward_fn = functools.partial(\n",
        "        environment_utilities.compute_optimal_reward_with_movielens_environment,\n",
        "        environment=tf_env)\n",
        "  optimal_action_fn = functools.partial(\n",
        "        environment_utilities.compute_optimal_action_with_movielens_environment,\n",
        "        environment=tf_env)\n",
        "  \n",
        "  regret_metric = tf_bandit_metrics.RegretMetric(\n",
        "      optimal_reward_fn, \n",
        "      name='regret'\n",
        "  )\n",
        "  suboptimal_arms_metric = tf_bandit_metrics.SuboptimalArmsMetric(\n",
        "      optimal_action_fn,\n",
        "      name='suboptimal_arms'\n",
        "  )\n",
        "  \n",
        "  return [regret_metric, suboptimal_arms_metric]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7zx1AUBe5_f"
      },
      "source": [
        "We will put it all together in `run` function to run the training loop of our implementation of bandits' movie recommendations. The driver below is a helper object and takes care of choosing actions using the policy, storing rewards of chosen actions in the replay buffer, calculating the predefined regret metric, and executing the agent's training step. You can find more info about the driver [here](https://www.tensorflow.org/agents/tutorials/4_drivers_tutorial)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5foepaVcv9Y"
      },
      "source": [
        "def run(\n",
        "    environment, \n",
        "    agent, \n",
        "    iterations, \n",
        "    steps_per_loop,\n",
        "    additional_metrics=()\n",
        "):\n",
        "  replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
        "      data_spec=agent.policy.trajectory_spec,\n",
        "      batch_size=environment.batch_size,\n",
        "      max_length=steps_per_loop)\n",
        "  \n",
        "  metrics = [] + list(additional_metrics)\n",
        "  ret_metrics = dict([(m.name, []) for m in metrics])\n",
        "\n",
        "  observers = [replay_buffer.add_batch] + metrics\n",
        "\n",
        "  driver = dynamic_step_driver.DynamicStepDriver(\n",
        "      env=environment,\n",
        "      policy=agent.collect_policy,\n",
        "      num_steps=steps_per_loop * environment.batch_size,\n",
        "      observers=observers)\n",
        "\n",
        "  regret_values = []\n",
        "\n",
        "  for _ in trange(num_iterations):\n",
        "    driver.run()\n",
        "    loss_info = agent.train(replay_buffer.gather_all())\n",
        "    replay_buffer.clear()\n",
        "    # Log metrics value\n",
        "    for metric in metrics:\n",
        "      ret_metrics[metric.name].append(metric.result())\n",
        "\n",
        "  return ret_metrics"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7gENChle_nn"
      },
      "source": [
        "Down below is the code for creating all necessary instances. Note that two parameters together specify the number of steps taken. `num_iterations` specifies how many times we run the trainer loop, while the driver will take `steps_per_loop` steps per iteration. The main reason behind keeping both of these parameters is that some operations are done per iteration, while the driver does some in every step. For example, the agent's train function is only called once per iteration. The trade-off here is that if we train more often, our policy is \"fresher\"; on the other hand, training in bigger batches might be more time-efficient. `batch_size` defines how many actions are generated through one step. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271,
          "referenced_widgets": [
            "17e2398238ce40169fdd423aff450100",
            "aa5fdd81e02e43b693b5653d3e2d6e1d",
            "47e05f3e7a734c1d93b6a619dd3fb1ef",
            "5e8e893643f7404b9036e3fa7f608c8a",
            "06775c0bf7d34ad9bf804b53307c8254",
            "51acde6b7335451aa598e02b0f65b51c",
            "687fb42d4b07486aab0112cea32a8159",
            "cf2f86b42c8a45b5b7d3c0cdf4cd0393"
          ]
        },
        "id": "9yxB1q29LqWV",
        "outputId": "5381898b-eabc-4705-d2da-2bad2b108ac8"
      },
      "source": [
        "batch_size =   32# @param {type:\"integer\"}\n",
        "num_iterations =   150# @param {type:\"integer\"}\n",
        "steps_per_loop =   2# @param {type:\"integer\"}\n",
        "agent_alpha = 2.0  # @param {type: \"number\"}\n",
        "tikhonov_weight = 0.001  # @param {type: \"number\"}\n",
        "\n",
        "env = MovieLensPyEnvironment(\n",
        "    './ml-100k/u.data', \n",
        "    rank_k=RANK_K,\n",
        "    batch_size=batch_size, \n",
        "    num_movies=NUM_ACTIONS\n",
        ")\n",
        "tf_env = tf_py_environment.TFPyEnvironment(env)\n",
        "tf_env.reset()\n",
        "\n",
        "agent = get_agent(\n",
        "    tf_env,\n",
        "    policy_class=LinearUCBPolicy,\n",
        "    tikhonov_weight=tikhonov_weight,\n",
        "    alpha=agent_alpha\n",
        ")\n",
        "\n",
        "additional_metrics = get_metrics(tf_env)\n",
        "\n",
        "metrics = run(\n",
        "    tf_env, \n",
        "    agent, \n",
        "    iterations=num_iterations,\n",
        "    steps_per_loop=steps_per_loop,\n",
        "    additional_metrics=additional_metrics\n",
        ")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "17e2398238ce40169fdd423aff450100",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=150.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tf_agents/drivers/dynamic_step_driver.py:203: calling while_loop_v2 (from tensorflow.python.ops.control_flow_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.while_loop(c, b, vars, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.while_loop(c, b, vars))\n",
            "WARNING:tensorflow:From <ipython-input-16-f0fa4f3e72bf>:28: ReplayBuffer.gather_all (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `as_dataset(..., single_deterministic_pass=True)` instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtoJvh6xeBxu"
      },
      "source": [
        "Now let's see the result. After running the last code snippet, the resulting plot (hopefully) shows that the average regret is going down as the agent is trained and the policy gets better in figuring out what the right action is, given the observation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "id": "jqo41BBZXLZh",
        "outputId": "5584256c-e935-41be-9864-4a58a54a5804"
      },
      "source": [
        "plot_regret(metrics['regret'], {'algorithm': 'LinUCB'})"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Rc93uPhd5I1"
      },
      "source": [
        "## Linear Thomson Sampling policy\n",
        "\n",
        "<center>\n",
        "  <img src=\"https://raw.githubusercontent.com/pstanisl/mlprague-2021/main/img/lints_algorithm.png\" alt=\"LinTS algorithm\" width=\"400\"/>\n",
        "</center>\n",
        "\n",
        "> A detailed explanation for the two above cases can be found in the paper\n",
        "[\"Thompson Sampling for Contextual Bandits with Linear Payoffs\"](http://proceedings.mlr.press/v28/agrawal13.pdf),\n",
        "Shipra Agrawal, Navin Goyal, ICML 2013\n",
        ", and its [supplementary material](http://proceedings.mlr.press/v28/agrawal13-supp.pdf)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKxJtkHrwTaS"
      },
      "source": [
        "class LinearTSPolicy(linear_bandit_policy.LinearBanditPolicy):\n",
        "  \"\"\"LinearTS policy is simplified version of LinearBanditPolicy from tf_agents.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               action_spec: types.BoundedTensorSpec,\n",
        "               variable_collection: tf.Module,\n",
        "               time_step_spec: Optional[types.TimeStep] = None,\n",
        "               alpha: float = 1.0,\n",
        "               tikhonov_weight: float = 1.0,\n",
        "               name: Optional[Text] = None):\n",
        "    super(LinearTSPolicy, self).__init__(\n",
        "        action_spec,\n",
        "        cov_matrix=variable_collection.cov_matrix_list,\n",
        "        data_vector=variable_collection.data_vector_list,\n",
        "        num_samples=variable_collection.num_samples_list,\n",
        "        time_step_spec=time_step_spec,\n",
        "        alpha=alpha,\n",
        "        tikhonov_weight=tikhonov_weight,\n",
        "        name=name)\n",
        "\n",
        "  def _distribution(self, time_step, policy_state):\n",
        "    observation = tf.nest.map_structure(lambda o: tf.cast(o, dtype=self._dtype),\n",
        "                                        time_step.observation)\n",
        "    \n",
        "    current_observation = tf.reshape(\n",
        "        observation, [-1, self._global_context_dim])\n",
        "\n",
        "    est_rewards = []\n",
        "    confidence_intervals = []\n",
        "\n",
        "    for model_index in range(self._num_actions):\n",
        "      # Compute confidence interval for action(i): x^T*A^-1*x\n",
        "      # 1: A^-1*x -> A^-1x\n",
        "      a_inv_x = linalg.conjugate_gradient_solve(\n",
        "          self._cov_matrix[model_index] + self._tikhonov_weight *\n",
        "          tf.eye(self._overall_context_dim, dtype=self._dtype),\n",
        "          tf.linalg.matrix_transpose(current_observation))\n",
        "      # 2: x^T*A^-1x -> confidence interval of action(i)\n",
        "      ci = tf.reshape(\n",
        "          tf.linalg.tensor_diag_part(tf.matmul(current_observation, a_inv_x)),\n",
        "          [-1, 1])\n",
        "      \n",
        "      confidence_intervals.append(ci)\n",
        "      est_mean_reward = tf.einsum('j,jk->k', self._data_vector[model_index],\n",
        "                                  a_inv_x)\n",
        "      est_rewards.append(est_mean_reward)\n",
        "    # Sample from the Normapl distribution\n",
        "    mu_sampler = tfp.distributions.Normal(\n",
        "          loc=tf.stack(est_rewards, axis=-1),\n",
        "          scale=self._alpha *\n",
        "          tf.sqrt(tf.squeeze(tf.stack(confidence_intervals, axis=-1), axis=1)))\n",
        "    rewards_for_argmax = mu_sampler.sample()\n",
        "    # Choose the best action for every observation in the batch\n",
        "    chosen_actions = tf.argmax(\n",
        "        rewards_for_argmax,\n",
        "        axis=-1,\n",
        "        output_type=tf.nest.flatten(self._action_spec)[0].dtype)\n",
        "\n",
        "    action_distributions = tfp.distributions.Deterministic(loc=chosen_actions)\n",
        "\n",
        "    policy_info = policy_utilities.populate_policy_info(\n",
        "        None, chosen_actions, rewards_for_argmax,\n",
        "        tf.stack(est_rewards, axis=-1), self._emit_policy_info,\n",
        "        False)\n",
        "\n",
        "    return policy_step.PolicyStep(\n",
        "        action_distributions, policy_state, policy_info)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltBIXUg9mI7u"
      },
      "source": [
        "Let's repeat the training with `LinearTSPolicy` and see the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYdibk130cGM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "eb18452a0b9b4b6f9a2e0acca2107348",
            "9605961d16894b37ae1b9a332df3ba04",
            "846642e0dc2646a49b75f92e102154e6",
            "4168a56c307f4906bb14f6f6c7ec5a4e",
            "137cb3364be448ccbe1919d6f6905c21",
            "22c27a5634aa4a65aa84f216a5537714",
            "e912e41fb5b04da8b230b2217c34bc0b",
            "2a14914eb9ce440c96af0d45b331fab5"
          ]
        },
        "outputId": "04a465fc-8da1-4d80-8e52-7121135b6981"
      },
      "source": [
        "batch_size =    32# @param {type:\"integer\"}\n",
        "num_iterations =   150# @param {type:\"integer\"}\n",
        "steps_per_loop =   2# @param {type:\"integer\"}\n",
        "agent_alpha = 2.0  # @param {type: \"number\"}\n",
        "tikhonov_weight = 0.001  # @param {type: \"number\"}\n",
        "\n",
        "tf_env.reset()\n",
        "\n",
        "agent = get_agent(\n",
        "  tf_env,\n",
        "  policy_class=LinearTSPolicy,\n",
        "  tikhonov_weight=tikhonov_weight,\n",
        "  alpha=agent_alpha\n",
        ")\n",
        "\n",
        "additional_metrics = get_metrics(tf_env)\n",
        "\n",
        "metrics = run(\n",
        "  tf_env, \n",
        "  agent, \n",
        "  iterations=num_iterations,\n",
        "  steps_per_loop=steps_per_loop,\n",
        "  additional_metrics=additional_metrics\n",
        ")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "linearTsPolicy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eb18452a0b9b4b6f9a2e0acca2107348",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=150.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "id": "LEAkVJWil4nG",
        "outputId": "a2f703da-be5c-4f23-9d46-5dccb02f68d9"
      },
      "source": [
        "plot_regret(metrics['regret'], {'algorithm': 'LinTS'})"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBsLy4I8l6bh"
      },
      "source": [
        ""
      ],
      "execution_count": 21,
      "outputs": []
    }
  ]
}