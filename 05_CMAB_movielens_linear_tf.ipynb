{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05_CMAB_movielens_linear_tf.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNVQW+kwQ2ogE27vDoaa2C/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8fb6ebc4cd8b4ba99e5e72324d265564": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3e898df8a93b499f8518faddbb5a39bd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5d96f92dd0f2417ba50b1fad37ccdf95",
              "IPY_MODEL_81d00aca25ab447a8ed4b4547df75199"
            ]
          }
        },
        "3e898df8a93b499f8518faddbb5a39bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5d96f92dd0f2417ba50b1fad37ccdf95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_97ec437b98534efab31da12606fdddb0",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 150,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 150,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ca1e3c859ac54cbfba35e8c0485977d3"
          }
        },
        "81d00aca25ab447a8ed4b4547df75199": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a3ec6a31bfd04026986356c5cdb73466",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 150/150 [01:52&lt;00:00,  1.33it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_45da8138ab9c44cf86960a2613b2106f"
          }
        },
        "97ec437b98534efab31da12606fdddb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ca1e3c859ac54cbfba35e8c0485977d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a3ec6a31bfd04026986356c5cdb73466": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "45da8138ab9c44cf86960a2613b2106f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2c4f88258e90491d89a92a49f704a1c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e5e8aa34e89c4277ae995d34889ff80a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1289477562d040828495de1bd3781435",
              "IPY_MODEL_99df2d82db0c4daa9d5266b9a30241e7"
            ]
          }
        },
        "e5e8aa34e89c4277ae995d34889ff80a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1289477562d040828495de1bd3781435": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_869b40441e224034aa6aacf6d519698d",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 150,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 150,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_52151e1755d64983a26909b49a8a2766"
          }
        },
        "99df2d82db0c4daa9d5266b9a30241e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d3de56e18d8d464f927a74e8f66a194d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 150/150 [01:46&lt;00:00,  1.41it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e6a8794874d24918bae848b1667bba23"
          }
        },
        "869b40441e224034aa6aacf6d519698d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "52151e1755d64983a26909b49a8a2766": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d3de56e18d8d464f927a74e8f66a194d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e6a8794874d24918bae848b1667bba23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pstanisl/mlprague-2021/blob/main/05_CMAB_movielens_linear_tf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ku9blLrybt_E"
      },
      "source": [
        "# Linear Contextual Multi-Armed Bandits \n",
        "\n",
        "From now we will use [TensorFlow Agents](https://www.tensorflow.org/agents), so so it's probably appropriate to say something about this library. Agents is a library for reinforcement learning in TensorFlow.  \n",
        "\n",
        "> TF-Agents makes designing, implementing, and testing new RL algorithms easier by providing well-tested modular components that can be modified and extended. It enables fast code iteration with good test integration and benchmarking.\n",
        "\n",
        "It provides API for creating all aspects necessary for reinforcement learning with Tensorflow, example of API can be seen below.\n",
        "\n",
        "```python\n",
        "import tensorflow as tf\n",
        "from tf_agents.networks import q_network\n",
        "from tf_agents.agents.dqn import dqn_agent\n",
        "\n",
        "q_net = q_network.QNetwork(\n",
        "  train_env.observation_spec(),\n",
        "  train_env.action_spec(),\n",
        "  fc_layer_params=(100,))\n",
        "\n",
        "agent = dqn_agent.DqnAgent(\n",
        "  train_env.time_step_spec(),\n",
        "  train_env.action_spec(),\n",
        "  q_network=q_net,\n",
        "  optimizer=optimizer,\n",
        "  td_errors_loss_fn=common.element_wise_squared_loss,\n",
        "  train_step_counter=tf.Variable(0))\n",
        "\n",
        "agent.initialize()\n",
        "```\n",
        "\n",
        "As Multi-Armed Bandits can be seen as a special case of RL, TF-Agents contains also building blocks for MAB, especially for Contextual Multi-Armed Bandits (CMAB). ☺️\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6fNTjpnu6eS"
      },
      "source": [
        "#### Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbVPxLuUR25T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b5f2ff6-478a-4566-ce21-d8677b241f52"
      },
      "source": [
        "!pip install tf-agents -q"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10kB 10.5MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 16.1MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 9.1MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 8.9MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51kB 4.5MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61kB 5.1MB/s eta 0:00:01\r\u001b[K     |██                              | 71kB 4.7MB/s eta 0:00:01\r\u001b[K     |██▏                             | 81kB 5.0MB/s eta 0:00:01\r\u001b[K     |██▍                             | 92kB 5.3MB/s eta 0:00:01\r\u001b[K     |██▊                             | 102kB 5.7MB/s eta 0:00:01\r\u001b[K     |███                             | 112kB 5.7MB/s eta 0:00:01\r\u001b[K     |███▎                            | 122kB 5.7MB/s eta 0:00:01\r\u001b[K     |███▌                            | 133kB 5.7MB/s eta 0:00:01\r\u001b[K     |███▉                            | 143kB 5.7MB/s eta 0:00:01\r\u001b[K     |████                            | 153kB 5.7MB/s eta 0:00:01\r\u001b[K     |████▎                           | 163kB 5.7MB/s eta 0:00:01\r\u001b[K     |████▋                           | 174kB 5.7MB/s eta 0:00:01\r\u001b[K     |████▉                           | 184kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 194kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 204kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 215kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 225kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 235kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 245kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 256kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████                         | 266kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 276kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 286kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 296kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 307kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 317kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 327kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████                       | 337kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 348kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 358kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 368kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████                      | 378kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 389kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 399kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 409kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 419kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 430kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 440kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 450kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 460kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 471kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 481kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 491kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 501kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 512kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 522kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 532kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 542kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 552kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 563kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 573kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 583kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 593kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████                | 604kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 614kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 624kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 634kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 645kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 655kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 665kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 675kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 686kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 696kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 706kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 716kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 727kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 737kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 747kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 757kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 768kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 778kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 788kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 798kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 808kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 819kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 829kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 839kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 849kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 860kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 870kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 880kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 890kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 901kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 911kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 921kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 931kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 942kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 952kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 962kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 972kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 983kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 993kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.0MB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.0MB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.0MB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.0MB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.0MB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.1MB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1MB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.1MB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.1MB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.1MB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1MB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.1MB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.1MB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1MB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1MB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.2MB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.2MB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2MB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2MB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.2MB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2MB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2MB 5.7MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2MMqktAoX5e",
        "outputId": "fff09e3f-2d9d-4d1b-a31e-babb3b164a71"
      },
      "source": [
        "!rm -f ./utils.py\n",
        "!wget --no-check-certificate --no-cache --no-cookies \\\n",
        "    https://raw.githubusercontent.com/pstanisl/mlprague-2021/main/utils.py \\\n",
        "    -O ./utils.py"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-26 09:47:07--  https://raw.githubusercontent.com/pstanisl/mlprague-2021/main/utils.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4941 (4.8K) [text/plain]\n",
            "Saving to: ‘./utils.py’\n",
            "\n",
            "\r./utils.py            0%[                    ]       0  --.-KB/s               \r./utils.py          100%[===================>]   4.83K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-02-26 09:47:07 (66.5 MB/s) - ‘./utils.py’ saved [4941/4941]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02ZZepbLdTS7"
      },
      "source": [
        "#### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUEquHXHRwwB"
      },
      "source": [
        "import functools\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf  # pylint: disable=g-explicit-tensorflow-version-import\n",
        "import tensorflow_probability as tfp\n",
        "import zipfile\n",
        "\n",
        "from tqdm.notebook import trange\n",
        "from typing import Optional, Sequence, Text, Tuple\n",
        "\n",
        "from tf_agents.agents import data_converter\n",
        "from tf_agents.agents import tf_agent\n",
        "from tf_agents.bandits.agents import linear_bandit_agent as lin_agent\n",
        "from tf_agents.bandits.agents import utils as bandit_utils\n",
        "from tf_agents.bandits.environments import environment_utilities\n",
        "from tf_agents.bandits.environments import bandit_py_environment\n",
        "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
        "from tf_agents.bandits.policies import linalg\n",
        "from tf_agents.bandits.policies import linear_bandit_policy\n",
        "from tf_agents.bandits.policies import policy_utilities\n",
        "from tf_agents.drivers import dynamic_step_driver\n",
        "from tf_agents.environments import tf_py_environment\n",
        "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
        "from tf_agents.policies import tf_policy\n",
        "from tf_agents.specs import array_spec\n",
        "from tf_agents.trajectories import policy_step\n",
        "from tf_agents.trajectories import time_step as ts\n",
        "from tf_agents.typing import types\n",
        "\n",
        "from utils import load_movielens_data, plot_regret"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b47tWwUVdgbV"
      },
      "source": [
        "#### Downloading the [MovieLens](https://grouplens.org/datasets/movielens/) (100K) dataset.\n",
        "\n",
        "**Dataset info**\n",
        "\n",
        "MovieLens data sets were collected by the GroupLens Research Project\n",
        "at the University of Minnesota.\n",
        "\n",
        "This data set consists of:\n",
        "* 100,000 ratings (1-5) from 943 users on 1682 movies.\n",
        "* Each user has rated at least 20 movies.\n",
        "* Simple demographic info for the users (age, gender, occupation, zip)\n",
        "\n",
        "The data was collected through the MovieLens web site\n",
        "(movielens.umn.edu) during the seven-month period from September 19th,\n",
        "1997 through April 22nd, 1998. This data has been cleaned up - users\n",
        "who had less than 20 ratings or did not have complete demographic\n",
        "information were removed from this data set. Detailed descriptions of\n",
        "the data file can be found at the end of this file.\n",
        "\n",
        "Neither the University of Minnesota nor any of the researchers\n",
        "involved can guarantee the correctness of the data, its suitability\n",
        "for any particular purpose, or the validity of results based on the\n",
        "use of the data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8_xdGprnyqb",
        "outputId": "cd416c91-2385-44a2-b9ae-92efd1bac1f4"
      },
      "source": [
        "print(\"Downloading movielens data...\")\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    http://files.grouplens.org/datasets/movielens/ml-100k.zip \\\n",
        "    -O ./movielens.zip\n",
        "\n",
        "zip_ref = zipfile.ZipFile('movielens.zip', \"r\")\n",
        "zip_ref.extractall()\n",
        "\n",
        "print(\"Done. Dataset contains:\")\n",
        "print(zip_ref.read('ml-100k/u.info').decode())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading movielens data...\n",
            "--2021-02-26 09:47:11--  http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4924029 (4.7M) [application/zip]\n",
            "Saving to: ‘./movielens.zip’\n",
            "\n",
            "./movielens.zip     100%[===================>]   4.70M  16.3MB/s    in 0.3s    \n",
            "\n",
            "2021-02-26 09:47:11 (16.3 MB/s) - ‘./movielens.zip’ saved [4924029/4924029]\n",
            "\n",
            "Done. Dataset contains:\n",
            "943 users\n",
            "1682 items\n",
            "100000 ratings\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBsEus-bdkRM"
      },
      "source": [
        "#### Parameters -- Feel Free to Play Around"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2Tf9d1NcbF9"
      },
      "source": [
        "RANK_K = 20 # @param {type:\"integer\"}\n",
        "NUM_ACTIONS = 20 # @param {type:\"integer\"}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvFAsPqLlmKQ"
      },
      "source": [
        "## Environment\n",
        "\n",
        "Implementation of the environment uses **MovieLens 100K dataset**. As described above, the dataset contains 100000 ratings from 943 users and 1682 movies. The environment can consider only the first $n$ of the dataset's movies. It can be set-up by `num_actions`. The number of \"known\" movies for the environment is equal to actions/arms.\n",
        "\n",
        "> Users without a rating (after selecting first $n$ movies) are removed from the environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW6QuzcKX8gq"
      },
      "source": [
        "class MovieLensPyEnvironment(bandit_py_environment.BanditPyEnvironment):\n",
        "  \"\"\"Implements the MovieLens Bandit environment.\n",
        "  This environment implements the MovieLens 100K dataset, available at:\n",
        "  https://www.kaggle.com/prajitdatta/movielens-100k-dataset\n",
        "  This dataset contains 100K ratings from 943 users on 1682 items.\n",
        "  This csv list of:\n",
        "  user id | item id | rating | timestamp.\n",
        "  This environment computes a low-rank matrix factorization (using SVD) of the\n",
        "  data matrix A, such that: A ~= U * V.\n",
        "  The reward of recommending item `j` to user `i` is provided as A_{ij}.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               data_dir: Text,\n",
        "               rank_k: int,\n",
        "               batch_size: int = 1,\n",
        "               num_movies: int = 20,\n",
        "               name: Optional[Text] = 'movielens'):\n",
        "    \"\"\"Initializes the MovieLens Bandit environment.\n",
        "    Args:\n",
        "      data_dir: (string) Directory where the data lies (in text form).\n",
        "      rank_k : (int) Which rank to use in the matrix factorization.\n",
        "      batch_size: (int) Number of observations generated per call.\n",
        "      num_movies: (int) Only the first `num_movies` movies will be used by the\n",
        "        environment. The rest is cut out from the data.\n",
        "      name: The name of this environment instance.\n",
        "    \"\"\"\n",
        "    self._num_actions = num_movies\n",
        "    self._batch_size = batch_size\n",
        "    self._context_dim = rank_k\n",
        "\n",
        "    # Compute the matrix factorization.\n",
        "    #self._data_matrix = dataset_utilities.load_movielens_data(data_dir)\n",
        "    self._data_matrix = load_movielens_data(data_dir)\n",
        "    # Keep only the first items.\n",
        "    self._data_matrix = self._data_matrix[:, :num_movies]\n",
        "    # Filter the users with no iterm rated.\n",
        "    nonzero_users = list(np.nonzero(np.sum(self._data_matrix, axis=1) > 0.0)[0])\n",
        "    self._data_matrix = self._data_matrix[nonzero_users, :]\n",
        "    self._effective_num_users = len(nonzero_users)\n",
        "\n",
        "    # Compute the SVD.\n",
        "    u, s, vh = np.linalg.svd(self._data_matrix, full_matrices=False)\n",
        "\n",
        "    # Keep only the largest singular values.\n",
        "    self._u_hat = u[:, :rank_k] * np.sqrt(s[:rank_k])\n",
        "    self._v_hat = np.transpose(\n",
        "        np.transpose(vh[:rank_k, :]) * np.sqrt(s[:rank_k]))\n",
        "    self._approx_ratings_matrix = np.matmul(self._u_hat, self._v_hat)\n",
        "\n",
        "    self._current_users = np.zeros(batch_size, dtype=np.int32)\n",
        "    self._previous_users = np.zeros(batch_size, dtype=np.int32)\n",
        "\n",
        "    self._action_spec = array_spec.BoundedArraySpec(\n",
        "        shape=(),\n",
        "        dtype=np.int32,\n",
        "        minimum=0,\n",
        "        maximum=self._num_actions - 1,\n",
        "        name='action')\n",
        "    observation_spec = array_spec.ArraySpec(\n",
        "        shape=(self._context_dim,), dtype=np.float64, name='observation')\n",
        "    self._time_step_spec = ts.time_step_spec(observation_spec)\n",
        "    self._observation = np.zeros((self._batch_size, self._context_dim))\n",
        "\n",
        "    self._optimal_action_table = np.argmax(\n",
        "        self._approx_ratings_matrix, axis=1)\n",
        "    self._optimal_reward_table = np.max(\n",
        "        self._approx_ratings_matrix, axis=1)\n",
        "\n",
        "    super(MovieLensPyEnvironment, self).__init__(\n",
        "        observation_spec, self._action_spec)\n",
        "\n",
        "  @property\n",
        "  def batch_size(self):\n",
        "    return self._batch_size\n",
        "\n",
        "  @property\n",
        "  def batched(self):\n",
        "    return True\n",
        "\n",
        "  def _observe(self):\n",
        "    \"\"\"Returns the u vectors of a random sample of users.\"\"\"\n",
        "    sampled_users = random.sample(\n",
        "        range(self._effective_num_users), self._batch_size)\n",
        "    self._previous_users = self._current_users\n",
        "    self._current_users = sampled_users\n",
        "    batched_observations = self._u_hat[sampled_users]\n",
        "    return batched_observations\n",
        "\n",
        "  def _apply_action(self, action):\n",
        "    \"\"\"Computes the reward for the input actions.\"\"\"\n",
        "    rewards = []\n",
        "    for i, j in zip(self._current_users, action):\n",
        "      rewards.append(self._approx_ratings_matrix[i, j])\n",
        "    return np.array(rewards)\n",
        "\n",
        "  def compute_optimal_action(self):\n",
        "    return self._optimal_action_table[self._previous_users]\n",
        "\n",
        "  def compute_optimal_reward(self):\n",
        "    return self._optimal_reward_table[self._previous_users]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rxo7RipFdrPk"
      },
      "source": [
        "Now we are equipped to initialize our environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWLNxLEiT05z"
      },
      "source": [
        "env = MovieLensPyEnvironment('./ml-100k/u.data', RANK_K, 1, num_movies=NUM_ACTIONS)\n",
        "tf_env = tf_py_environment.TFPyEnvironment(env)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4IcbZr5duJt"
      },
      "source": [
        "Below we can check what this environment produces."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcRZbsaSUCEh",
        "outputId": "b369a13c-50b1-42d4-a4bf-8f8eda53d5da"
      },
      "source": [
        "print('Observation spec:', tf_env.observation_spec())\n",
        "print('An observation: ', tf_env.reset().observation.numpy())\n",
        "\n",
        "action = tf.zeros(1, dtype=tf.int32)\n",
        "time_step = tf_env.step(action)\n",
        "\n",
        "print(f'For users={env._previous_users}, we selected action={action.numpy()} (optimal={tf_env.compute_optimal_action()})')\n",
        "print(f'For users={env._previous_users}, we received reward={time_step.reward.numpy()} (optimal={tf_env.compute_optimal_reward()})')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Observation spec: TensorSpec(shape=(20,), dtype=tf.float64, name='observation')\n",
            "An observation:  [[-0.79730337 -0.49021872  0.51813965 -0.00599527  0.0340123  -0.27043032\n",
            "  -0.4372217  -0.14761941  0.40706025 -0.37625871  0.35358919  0.22909637\n",
            "  -0.06227485  0.00343793 -0.13005297 -0.3767689  -0.14442474 -0.16103344\n",
            "  -0.00862367  0.01625144]]\n",
            "For users=[89], we selected action=[0] (optimal=[8])\n",
            "For users=[89], we received reward=[3.433588e-14] (optimal=[5.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTjTE8ThV85o"
      },
      "source": [
        "## Policy - LinerUCB\n",
        "\n",
        "As we leant in UCB example, the Upper Confidence Bounds (UCB) algorithm measures potential by an upper confidence bound of the reward value, $\\hat{U}_{t}(a)$, so that the true value is below with bound $Q(a) \\leq \\hat{Q}_t(a) + \\hat{U}_t(a)$ with high probability. The upper bound $\\hat{U}_t(a)$ is a function of $N_t(a)$; a larger number of trials $N_t(a)$ should give us a smaller bound $\\hat{U}_t(a)$, see picture below.\n",
        "\n",
        "<center>\n",
        "  <img src=\"https://miro.medium.com/max/4800/1*p_4mvZ6r6ddbShd7tOT0sw.png\" alt=\"source: https://towardsdatascience.com/recommender-systems-using-linucb-a-contextual-multi-armed-bandit-approach-35a6f0eb6c4\" width=\"600\"/>\n",
        "</center>\n",
        "\n",
        "<!--![](https://miro.medium.com/max/4800/1*p_4mvZ6r6ddbShd7tOT0sw.png \"source: https://towardsdatascience.com/recommender-systems-using-linucb-a-contextual-multi-armed-bandit-approach-35a6f0eb6c4\")-->\n",
        "\n",
        "For contextual bandits UCB, the expected payoff of an action is assumed to be linear in its d-dimensional feature vector $X$ with some unknown coefficient vector $\\theta$.\n",
        "\n",
        "$$\n",
        "E\\left[r_{t,a}|x_{t,a}\\right] = x^{T}_{t,a}\\theta^{\\ast}_{a}\n",
        "$$\n",
        "\n",
        "An upper confidence bound has to be calculated for each action for the algorithm to be able to choose an arm at every trial. The strategy for choosing the action at every trial $t$ is formalised as\n",
        "\n",
        "$$\n",
        "a_{t} \\stackrel{def}{=} argmax\\left(x^{T}_{t,a}\\hat{\\theta}_{a} + \\alpha \\sqrt{x^{T}_{t,a} A^{-1} x_{t,a}} \\right),\n",
        "$$\n",
        "\n",
        "where $\\hat{\\theta} = A^{-1}b$.\n",
        "\n",
        "<br/>\n",
        "\n",
        "**TASK**: Fill in the missing pieces of code and create:\n",
        "\n",
        "1. computation of the confidence intervals,\n",
        "1. choosing the next action."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10eDwxGDV-n6"
      },
      "source": [
        "class LinearUCBPolicy(linear_bandit_policy.LinearBanditPolicy):\n",
        "  \"\"\"LinearUCB policy is simplified version of LinearBanditPolicy from tf_agente.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               action_spec: types.BoundedTensorSpec,\n",
        "               variable_collection: tf.Module,\n",
        "               time_step_spec: Optional[types.TimeStep] = None,\n",
        "               alpha: float = 1.0,\n",
        "               tikhonov_weight: float = 1.0,\n",
        "               name: Optional[Text] = None):\n",
        "    super(LinearUCBPolicy, self).__init__(\n",
        "        action_spec,\n",
        "        cov_matrix=variable_collection.cov_matrix_list,\n",
        "        data_vector=variable_collection.data_vector_list,\n",
        "        num_samples=variable_collection.num_samples_list,\n",
        "        time_step_spec=time_step_spec,\n",
        "        alpha=alpha,\n",
        "        tikhonov_weight=tikhonov_weight,\n",
        "        name=name)\n",
        "\n",
        "  def _distribution(self, time_step, policy_state):\n",
        "    observation = tf.nest.map_structure(lambda o: tf.cast(o, dtype=self._dtype),\n",
        "                                        time_step.observation)\n",
        "    \n",
        "    current_observation = tf.reshape(\n",
        "        observation, [-1, self._global_context_dim])\n",
        "\n",
        "    est_rewards = []\n",
        "    confidence_intervals = []\n",
        "\n",
        "    for model_index in range(self._num_actions):\n",
        "      a = self._cov_matrix[model_index]\n",
        "      b = self._data_vector[model_index]\n",
        "      # Compute confidence interval for action(i): x^T*A^-1*x\n",
        "      # 1: A^-1*x -> A^-1x - A = a + tikhonow * I\n",
        "      a_inv_x = linalg.conjugate_gradient_solve(\n",
        "          a + self._tikhonov_weight *\n",
        "          tf.eye(self._overall_context_dim, dtype=self._dtype),\n",
        "          tf.linalg.matrix_transpose(current_observation)) # YOUR CODE HERE\n",
        "      # 2: x^T*A^-1x -> confidence interval of action(i)\n",
        "      ci = tf.reshape(\n",
        "          tf.linalg.tensor_diag_part(tf.matmul(current_observation, a_inv_x)), # YOUR CODE HERE\n",
        "          [-1, 1])\n",
        "      \n",
        "      confidence_intervals.append(ci)\n",
        "      est_mean_reward = tf.einsum('j,jk->k', b,\n",
        "                                  a_inv_x)\n",
        "      est_rewards.append(est_mean_reward)\n",
        "    # Estimate rewards for every action\n",
        "    optimistic_estimates = [\n",
        "        tf.reshape(mean_reward, [-1, 1]) + self._alpha * tf.sqrt(confidence)\n",
        "        for mean_reward, confidence in zip(est_rewards, confidence_intervals)\n",
        "    ]\n",
        "    # Keeping the batch dimension during the squeeze, even if batch_size == 1.\n",
        "    rewards_for_argmax = tf.squeeze(\n",
        "        tf.stack(optimistic_estimates, axis=-1), axis=[1])\n",
        "    \n",
        "    # Choose the best action for every observation in the batch\n",
        "    chosen_actions = tf.argmax(\n",
        "        rewards_for_argmax, # YOUR CODE HERE\n",
        "        axis=-1,\n",
        "        output_type=tf.nest.flatten(self._action_spec)[0].dtype)\n",
        "\n",
        "    action_distributions = tfp.distributions.Deterministic(loc=chosen_actions)\n",
        "\n",
        "    policy_info = policy_utilities.populate_policy_info(\n",
        "        None, chosen_actions, rewards_for_argmax,\n",
        "        tf.stack(est_rewards, axis=-1), self._emit_policy_info,\n",
        "        False)\n",
        "\n",
        "    return policy_step.PolicyStep(\n",
        "        action_distributions, policy_state, policy_info)\n",
        "    "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uo3YPdpkxYsr"
      },
      "source": [
        "## Agent\n",
        "\n",
        "For contextual bandits UCB, the expected payoff of an action is assumed to be linear in its d-dimensional feature vector $X$ with some unknown coefficient vector $\\theta$.\n",
        "\n",
        "$$\n",
        "E\\left[r_{t,a}|x_{t,a}\\right] = x^{T}_{t,a}\\theta^{\\ast}_{a}\n",
        "$$\n",
        "\n",
        "This model is called disjoint since the parameters are not shared among different actions/arms. To solve for the coefficient vector $\\theta$ in the above equation ridge regression ([Tikhonov regularization](https://en.wikipedia.org/wiki/Tikhonov_regularization)) is applied to the training data. The whole algorithm is described below\n",
        "\n",
        "<center>\n",
        "  <img src=\"https://raw.githubusercontent.com/pstanisl/mlprague-2021/main/img/linucb_algorithm.png\" alt=\"LinUCB algorithm\" width=\"400\"/>\n",
        "</center>\n",
        "\n",
        "<!--![linucb_algorithm.png](https://raw.githubusercontent.com/pstanisl/mlprague-2021/main/img/linucb_algorithm.png =100x)-->\n",
        "\n",
        "> More details about the algorithm can be found in the [A contextual-bandit approach to\n",
        "personalized news article recommendation](https://arxiv.org/pdf/1003.0146.pdf) and [Linear Upper Confidence Bound Algorithm for Contextual Bandit Problem with Piled Rewards](https://khhuang.me/docs/pakdd2016linucbpr.pdf) papers.\n",
        "\n",
        "The LinearAgent with `LinearUCBPolicy` agent implements the identically named Bandit algorithm, which estimates the parameter of the linear reward function while also maintains a confidence ellipsoid around the estimate. The agent chooses the action/arm that has the highest estimated expected reward, assuming that the parameter lies within the confidence ellipsoid."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2zoC7YYVzxj"
      },
      "source": [
        "def sum_reward_weighted_observations(r: types.Tensor,\n",
        "                                     x: types.Tensor) -> types.Tensor:\n",
        "  \"\"\"Calculates an update used by some Bandit algorithms.\n",
        "  Given an observation `x` and corresponding reward `r`, the weigthed\n",
        "  observations vector (denoted `b` here) should be updated as `b = b + r * x`.\n",
        "  This function calculates the sum of weighted rewards for batched\n",
        "  observations `x`.\n",
        "\n",
        "  Args:\n",
        "    r: a `Tensor` of shape [`batch_size`]. This is the rewards of the batched\n",
        "      observations.\n",
        "    x: a `Tensor` of shape [`batch_size`, `context_dim`]. This is the matrix\n",
        "      with the (batched) observations.\n",
        "      \n",
        "  Returns:\n",
        "    The update that needs to be added to `b`. Has the same shape as `b`.\n",
        "    If the observation matrix `x` is empty, a zero vector is returned.\n",
        "  \"\"\"\n",
        "  batch_size = tf.shape(x)[0]\n",
        "\n",
        "  return tf.reduce_sum(tf.reshape(r, [batch_size, 1]) * x, axis=0)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMo6hdUpD6hO"
      },
      "source": [
        "class LinearAgent(lin_agent.LinearBanditAgent):\n",
        "  \"\"\"Simplified implentation of an agent that maintains linear reward \n",
        "  estimates and their uncertainties.\n",
        "  \n",
        "  Original implementation can be found here: http://bit.ly/3kk7v3D\n",
        "  \"\"\"\n",
        "  def __init__(self,\n",
        "              time_step_spec: types.TimeStep,\n",
        "              action_spec: types.BoundedTensorSpec,\n",
        "              policy_class: linear_bandit_policy.LinearBanditPolicy = LinearUCBPolicy,\n",
        "              alpha: float = 1.0,\n",
        "              tikhonov_weight: float = 1.0,\n",
        "              dtype: tf.DType = tf.float32,\n",
        "              name: Optional[Text] = None):\n",
        "\n",
        "    super(LinearAgent, self).__init__(\n",
        "        lin_agent.ExplorationPolicy.linear_ucb_policy,\n",
        "        time_step_spec=time_step_spec,\n",
        "        action_spec=action_spec,\n",
        "        alpha=alpha,\n",
        "        tikhonov_weight=tikhonov_weight,\n",
        "        dtype=dtype,\n",
        "        name=name\n",
        "    )\n",
        "\n",
        "    self._as_trajectory = data_converter.AsTrajectory(\n",
        "      self.data_context, sequence_length=None)\n",
        "\n",
        "    self._policy = self._policy = policy_class(\n",
        "        action_spec=action_spec,\n",
        "        variable_collection=self._variable_collection,\n",
        "        time_step_spec=time_step_spec,\n",
        "        alpha=alpha,\n",
        "        tikhonov_weight=tikhonov_weight\n",
        "    )\n",
        "  \n",
        "  def _train(self, experience, weights=None):\n",
        "    \"\"\"Updates the policy based on the data in `experience`.\n",
        "    Note that `experience` should only contain data points that this agent has\n",
        "    not previously seen. If `experience` comes from a replay buffer, this buffer\n",
        "    should be cleared between each call to `train`.\n",
        "    Args:\n",
        "      experience: A batch of experience data in the form of a `Trajectory`.\n",
        "      weights: Unused.\n",
        "    Returns:\n",
        "        A `LossInfo` containing the loss *before* the training step is taken.\n",
        "        In most cases, if `weights` is provided, the entries of this tuple will\n",
        "        have been calculated with the weights.  Note that each Agent chooses\n",
        "        its own method of applying weights.\n",
        "    \"\"\"\n",
        "    experience = self._as_trajectory(experience)\n",
        "\n",
        "    del weights  # unused\n",
        "\n",
        "    reward, action, observation, batch_size = self._process_experience(\n",
        "        experience)\n",
        "    \n",
        "    for k in range(self._num_models):\n",
        "      # Create identity matrix used as a mask\n",
        "      diag_mask = tf.linalg.tensor_diag(\n",
        "          tf.cast(tf.equal(action, k), self._dtype))\n",
        "      # Get an observation for the action from the observation\n",
        "      observations_for_arm = tf.matmul(diag_mask, observation)\n",
        "      rewards_for_arm = tf.matmul(diag_mask, tf.reshape(reward, [-1, 1]))\n",
        "      num_samples_for_arm_current = tf.reduce_sum(diag_mask)\n",
        "      \n",
        "      tf.compat.v1.assign_add(self._num_samples_list[k],\n",
        "                              num_samples_for_arm_current)\n",
        "      num_samples_for_arm_total = self._num_samples_list[k].read_value()\n",
        "\n",
        "      # Update the covariance matrix `a` and the weighted sum of rewards `b`\n",
        "      # using a forgetting factor `gamma`.\n",
        "      \n",
        "      # YOUR CODE GOES HERE\n",
        "      x = observations_for_arm\n",
        "      r = rewards_for_arm\n",
        "      a_prev = self._cov_matrix_list[k]\n",
        "      b_prev = self._data_vector_list[k]\n",
        "\n",
        "      a_new = self._gamma * a_prev + tf.matmul(x, x, transpose_a=True)\n",
        "      b_new = self._gamma * b_prev + sum_reward_weighted_observations(r, x)\n",
        "      # END OF YOUR CODE\n",
        "\n",
        "      # Update real variables\n",
        "      tf.compat.v1.assign(self._cov_matrix_list[k], a_new) # YOUR CODE HERE\n",
        "      tf.compat.v1.assign(self._data_vector_list[k], b_new) # YOUR CODE HERE\n",
        "\n",
        "    loss = -1. * tf.reduce_sum(reward) # YOUR CODE HERE\n",
        "    self.compute_summaries(loss)\n",
        "\n",
        "    self._train_step_counter.assign_add(batch_size)\n",
        "\n",
        "    return tf_agent.LossInfo(loss=(loss), extra=())"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Huc03djLkNyt"
      },
      "source": [
        "Helper function for creating an instance of the `LinearAgent` with a linear policy like our `LinearUCBPolicy`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkJm2_WpgfaL"
      },
      "source": [
        "def get_agent(\n",
        "    environment, \n",
        "    policy_class: linear_bandit_policy.LinearBanditPolicy = LinearUCBPolicy,\n",
        "    tikhonov_weight: float = 0.001, \n",
        "    alpha: float = 10.0\n",
        "):  \n",
        "  return LinearAgent(\n",
        "    time_step_spec=environment.time_step_spec(),\n",
        "    action_spec=environment.action_spec(),\n",
        "    policy_class=policy_class,\n",
        "    tikhonov_weight=tikhonov_weight,\n",
        "    alpha=alpha,\n",
        "    dtype=tf.float32\n",
        "  )"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bG8LVv2rW1sK"
      },
      "source": [
        "agent = get_agent(\n",
        "    tf_env, policy_class=LinearUCBPolicy, tikhonov_weight=0.001, alpha=10.0)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nE2kDQ2kcSo"
      },
      "source": [
        "Let have a look at the data specification in the agent. The `training_data_spec` attribute of the agent specifies what elements and structure the training data should have. The `training_data_spec.observation` specificate the structure of the context vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPg7h-hIlTnx",
        "outputId": "4f95397a-f914-4ce5-ab9d-86dc993a0d7c"
      },
      "source": [
        "print('training data spec: ', agent.training_data_spec)\n",
        "print('observation spec in training: ', agent.training_data_spec.observation)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training data spec:  Trajectory(step_type=TensorSpec(shape=(), dtype=tf.int32, name='step_type'), observation=TensorSpec(shape=(20,), dtype=tf.float64, name='observation'), action=BoundedTensorSpec(shape=(), dtype=tf.int32, name='action', minimum=array(0, dtype=int32), maximum=array(19, dtype=int32)), policy_info=PolicyInfo(log_probability=(), predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=()), next_step_type=TensorSpec(shape=(), dtype=tf.int32, name='step_type'), reward=TensorSpec(shape=(), dtype=tf.float32, name='reward'), discount=BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)))\n",
            "observation spec in training:  TensorSpec(shape=(20,), dtype=tf.float64, name='observation')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDjYCtBUl2j4"
      },
      "source": [
        "## Training\n",
        "\n",
        "Now we put together all the components that we introduced above: the environment, the policy, and the agent. We run the policy on the environment and output training data with the help of a driver, and train the agent on the data.\n",
        "\n",
        "#### Metrics\n",
        "\n",
        "Important of the training are metrics. If you read some materials you can find, that bandits' most important metric is regret, calculated as the difference between the reward collected by the agent and the expected reward of an oracle policy that has access to the reward functions of the environment. The [RegretMetric](https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/metrics/tf_metrics.py) thus needs a `baseline_reward_fn` function that calculates the best achievable expected reward given an observation. In our example, the optimal reward is computed in the `MovieLensPyEnvironment.compute_optimal_reward` from the approximation of the rating.\n",
        "\n",
        "> In reality, we usually do not have access to an oracle policy, so the regret is hard to get. Thus, the cumulative reward or other metric is often used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTmTQNtQpk_a"
      },
      "source": [
        "def get_metrics(environment):\n",
        "  optimal_reward_fn = functools.partial(\n",
        "        environment_utilities.compute_optimal_reward_with_movielens_environment,\n",
        "        environment=tf_env)\n",
        "  optimal_action_fn = functools.partial(\n",
        "        environment_utilities.compute_optimal_action_with_movielens_environment,\n",
        "        environment=tf_env)\n",
        "  \n",
        "  regret_metric = tf_bandit_metrics.RegretMetric(\n",
        "      optimal_reward_fn, \n",
        "      name='regret'\n",
        "  )\n",
        "  suboptimal_arms_metric = tf_bandit_metrics.SuboptimalArmsMetric(\n",
        "      optimal_action_fn,\n",
        "      name='suboptimal_arms'\n",
        "  )\n",
        "  \n",
        "  return [regret_metric, suboptimal_arms_metric]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7zx1AUBe5_f"
      },
      "source": [
        "We will put it all together in `run` function to run the training loop of our implementation of bandits' movie recommendations. The driver below is a helper object and takes care of choosing actions using the policy, storing rewards of chosen actions in the replay buffer, calculating the predefined regret metric, and executing the agent's training step. You can find more info about the driver [here](https://www.tensorflow.org/agents/tutorials/4_drivers_tutorial)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5foepaVcv9Y"
      },
      "source": [
        "def run(\n",
        "    environment, \n",
        "    agent, \n",
        "    iterations, \n",
        "    steps_per_loop,\n",
        "    additional_metrics=()\n",
        "):\n",
        "  replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
        "      data_spec=agent.policy.trajectory_spec,\n",
        "      batch_size=environment.batch_size,\n",
        "      max_length=steps_per_loop)\n",
        "  \n",
        "  metrics = [] + list(additional_metrics)\n",
        "  ret_metrics = dict([(m.name, []) for m in metrics])\n",
        "\n",
        "  observers = [replay_buffer.add_batch] + metrics\n",
        "\n",
        "  driver = dynamic_step_driver.DynamicStepDriver(\n",
        "      env=environment,\n",
        "      policy=agent.collect_policy,\n",
        "      num_steps=steps_per_loop * environment.batch_size,\n",
        "      observers=observers)\n",
        "\n",
        "  regret_values = []\n",
        "\n",
        "  for _ in trange(num_iterations):\n",
        "    driver.run()\n",
        "    loss_info = agent.train(replay_buffer.gather_all())\n",
        "    replay_buffer.clear()\n",
        "    # Log metrics value\n",
        "    for metric in metrics:\n",
        "      ret_metrics[metric.name].append(metric.result())\n",
        "\n",
        "  return ret_metrics"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7gENChle_nn"
      },
      "source": [
        "Down below is the code for creating all necessary instances. Note that two parameters together specify the number of steps taken. `num_iterations` specifies how many times we run the trainer loop, while the driver will take `steps_per_loop` steps per iteration. The main reason behind keeping both of these parameters is that some operations are done per iteration, while the driver does some in every step. For example, the agent's train function is only called once per iteration. The trade-off here is that if we train more often, our policy is \"fresher\"; on the other hand, training in bigger batches might be more time-efficient. `batch_size` defines how many actions are generated through one step. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271,
          "referenced_widgets": [
            "8fb6ebc4cd8b4ba99e5e72324d265564",
            "3e898df8a93b499f8518faddbb5a39bd",
            "5d96f92dd0f2417ba50b1fad37ccdf95",
            "81d00aca25ab447a8ed4b4547df75199",
            "97ec437b98534efab31da12606fdddb0",
            "ca1e3c859ac54cbfba35e8c0485977d3",
            "a3ec6a31bfd04026986356c5cdb73466",
            "45da8138ab9c44cf86960a2613b2106f"
          ]
        },
        "id": "9yxB1q29LqWV",
        "outputId": "5e9c2ec9-c918-4a69-b5a5-bfea64ca033e"
      },
      "source": [
        "batch_size =   32# @param {type:\"integer\"}\n",
        "num_iterations =   150# @param {type:\"integer\"}\n",
        "steps_per_loop =   2# @param {type:\"integer\"}\n",
        "agent_alpha = 2.0  # @param {type: \"number\"}\n",
        "tikhonov_weight = 0.001  # @param {type: \"number\"}\n",
        "\n",
        "env = MovieLensPyEnvironment(\n",
        "    './ml-100k/u.data', \n",
        "    rank_k=RANK_K,\n",
        "    batch_size=batch_size, \n",
        "    num_movies=NUM_ACTIONS\n",
        ")\n",
        "tf_env = tf_py_environment.TFPyEnvironment(env)\n",
        "tf_env.reset()\n",
        "\n",
        "agent = get_agent(\n",
        "    tf_env,\n",
        "    policy_class=LinearUCBPolicy,\n",
        "    tikhonov_weight=tikhonov_weight,\n",
        "    alpha=agent_alpha\n",
        ")\n",
        "\n",
        "additional_metrics = get_metrics(tf_env)\n",
        "\n",
        "metrics = run(\n",
        "    tf_env, \n",
        "    agent, \n",
        "    iterations=num_iterations,\n",
        "    steps_per_loop=steps_per_loop,\n",
        "    additional_metrics=additional_metrics\n",
        ")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8fb6ebc4cd8b4ba99e5e72324d265564",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=150.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tf_agents/drivers/dynamic_step_driver.py:203: calling while_loop_v2 (from tensorflow.python.ops.control_flow_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.while_loop(c, b, vars, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.while_loop(c, b, vars))\n",
            "WARNING:tensorflow:From <ipython-input-16-f0fa4f3e72bf>:28: ReplayBuffer.gather_all (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `as_dataset(..., single_deterministic_pass=True)` instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtoJvh6xeBxu"
      },
      "source": [
        "Now let's see the result. After running the last code snippet, the resulting plot (hopefully) shows that the average regret is going down as the agent is trained and the policy gets better in figuring out what the right action is, given the observation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "id": "jqo41BBZXLZh",
        "outputId": "452f905f-318d-466f-c238-af86028333f8"
      },
      "source": [
        "plot_regret(metrics['regret'], {'algorithm': 'LinUCB'})"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Rc93uPhd5I1"
      },
      "source": [
        "## Linear Thomson Sampling policy\n",
        "\n",
        "<center>\n",
        "  <img src=\"https://raw.githubusercontent.com/pstanisl/mlprague-2021/main/img/lints_algorithm.png\" alt=\"LinTS algorithm\" width=\"400\"/>\n",
        "</center>\n",
        "\n",
        "> A detailed explanation for the two above cases can be found in the paper\n",
        "[\"Thompson Sampling for Contextual Bandits with Linear Payoffs\"](http://proceedings.mlr.press/v28/agrawal13.pdf),\n",
        "Shipra Agrawal, Navin Goyal, ICML 2013\n",
        ", and its [supplementary material](http://proceedings.mlr.press/v28/agrawal13-supp.pdf)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKxJtkHrwTaS"
      },
      "source": [
        "class LinearTSPolicy(linear_bandit_policy.LinearBanditPolicy):\n",
        "  \"\"\"LinearTS policy is simplified version of LinearBanditPolicy from tf_agents.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               action_spec: types.BoundedTensorSpec,\n",
        "               variable_collection: tf.Module,\n",
        "               time_step_spec: Optional[types.TimeStep] = None,\n",
        "               alpha: float = 1.0,\n",
        "               tikhonov_weight: float = 1.0,\n",
        "               name: Optional[Text] = None):\n",
        "    super(LinearTSPolicy, self).__init__(\n",
        "        action_spec,\n",
        "        cov_matrix=variable_collection.cov_matrix_list,\n",
        "        data_vector=variable_collection.data_vector_list,\n",
        "        num_samples=variable_collection.num_samples_list,\n",
        "        time_step_spec=time_step_spec,\n",
        "        alpha=alpha,\n",
        "        tikhonov_weight=tikhonov_weight,\n",
        "        name=name)\n",
        "\n",
        "  def _distribution(self, time_step, policy_state):\n",
        "    observation = tf.nest.map_structure(lambda o: tf.cast(o, dtype=self._dtype),\n",
        "                                        time_step.observation)\n",
        "    \n",
        "    current_observation = tf.reshape(\n",
        "        observation, [-1, self._global_context_dim])\n",
        "\n",
        "    est_rewards = []\n",
        "    confidence_intervals = []\n",
        "\n",
        "    for model_index in range(self._num_actions):\n",
        "      # Compute confidence interval for action(i): x^T*A^-1*x\n",
        "      # YOUR CODE GOES HERE\n",
        "      # 1: A^-1*x -> A^-1x\n",
        "      a_inv_x = linalg.conjugate_gradient_solve(\n",
        "          self._cov_matrix[model_index] + self._tikhonov_weight *\n",
        "          tf.eye(self._overall_context_dim, dtype=self._dtype),\n",
        "          tf.linalg.matrix_transpose(current_observation))\n",
        "      # 2: x^T*A^-1x -> confidence interval of action(i)\n",
        "      ci = tf.reshape(\n",
        "          tf.linalg.tensor_diag_part(tf.matmul(current_observation, a_inv_x)),\n",
        "          [-1, 1])\n",
        "      # END OF YOUR CODE\n",
        "      \n",
        "      confidence_intervals.append(ci)\n",
        "      est_mean_reward = tf.einsum('j,jk->k', self._data_vector[model_index],\n",
        "                                  a_inv_x)\n",
        "      est_rewards.append(est_mean_reward)\n",
        "    # Sample from the Normapl distribution\n",
        "    mu_sampler = tfp.distributions.Normal(\n",
        "          loc=tf.stack(est_rewards, axis=-1), # YOUR CODE HERE\n",
        "          scale=self._alpha *\n",
        "          tf.sqrt(tf.squeeze(tf.stack(confidence_intervals, axis=-1), axis=1))) # YOUR CODE HERE\n",
        "    rewards_for_argmax = mu_sampler.sample()\n",
        "    # Choose the best action for every observation in the batch\n",
        "    chosen_actions = tf.argmax(\n",
        "        rewards_for_argmax, # YOUR CODE HERE\n",
        "        axis=-1,\n",
        "        output_type=tf.nest.flatten(self._action_spec)[0].dtype)\n",
        "\n",
        "    action_distributions = tfp.distributions.Deterministic(loc=chosen_actions)\n",
        "\n",
        "    policy_info = policy_utilities.populate_policy_info(\n",
        "        None, chosen_actions, rewards_for_argmax,\n",
        "        tf.stack(est_rewards, axis=-1), self._emit_policy_info,\n",
        "        False)\n",
        "\n",
        "    return policy_step.PolicyStep(\n",
        "        action_distributions, policy_state, policy_info)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltBIXUg9mI7u"
      },
      "source": [
        "Let's repeat the training with `LinearTSPolicy` and see the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYdibk130cGM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "2c4f88258e90491d89a92a49f704a1c2",
            "e5e8aa34e89c4277ae995d34889ff80a",
            "1289477562d040828495de1bd3781435",
            "99df2d82db0c4daa9d5266b9a30241e7",
            "869b40441e224034aa6aacf6d519698d",
            "52151e1755d64983a26909b49a8a2766",
            "d3de56e18d8d464f927a74e8f66a194d",
            "e6a8794874d24918bae848b1667bba23"
          ]
        },
        "outputId": "4c5e5404-7930-4b2b-f7ce-d2a732290310"
      },
      "source": [
        "batch_size =    32# @param {type:\"integer\"}\n",
        "num_iterations =   150# @param {type:\"integer\"}\n",
        "steps_per_loop =   2# @param {type:\"integer\"}\n",
        "agent_alpha = 2.0  # @param {type: \"number\"}\n",
        "tikhonov_weight = 0.001  # @param {type: \"number\"}\n",
        "\n",
        "tf_env.reset()\n",
        "\n",
        "agent = get_agent(\n",
        "  tf_env,\n",
        "  policy_class=LinearTSPolicy,\n",
        "  tikhonov_weight=tikhonov_weight,\n",
        "  alpha=agent_alpha\n",
        ")\n",
        "\n",
        "additional_metrics = get_metrics(tf_env)\n",
        "\n",
        "metrics = run(\n",
        "  tf_env, \n",
        "  agent, \n",
        "  iterations=num_iterations,\n",
        "  steps_per_loop=steps_per_loop,\n",
        "  additional_metrics=additional_metrics\n",
        ")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c4f88258e90491d89a92a49f704a1c2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=150.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "id": "LEAkVJWil4nG",
        "outputId": "66b1f020-8096-4ffc-f2cb-0a523f665ac3"
      },
      "source": [
        "plot_regret(metrics['regret'], {'algorithm': 'LinTS'})"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBsLy4I8l6bh"
      },
      "source": [
        ""
      ],
      "execution_count": 21,
      "outputs": []
    }
  ]
}