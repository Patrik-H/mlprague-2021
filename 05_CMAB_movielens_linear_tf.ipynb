{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05_CMAB_movielens_linear_tf.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOeFeYaSMJ4CQp+barZJsRC",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "18f1a3fdfd4e4514b4ec95deae262f0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cee2c23e4b084b08a6064309064cb9b5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_36138681401a4f44adfcee98f32bdd5b",
              "IPY_MODEL_405234c3e9634d1ea9d85caf0a631b8e"
            ]
          }
        },
        "cee2c23e4b084b08a6064309064cb9b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "36138681401a4f44adfcee98f32bdd5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_184c97e9990d4a0d8082a1790fa40315",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 150,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 150,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e75b3f3bc954418794aae38440ea1b41"
          }
        },
        "405234c3e9634d1ea9d85caf0a631b8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e29c22fa3b7241f2a21fbe59a5f11beb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 150/150 [01:48&lt;00:00,  1.38it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4df7d3146c414792b57e4a496d87ce0b"
          }
        },
        "184c97e9990d4a0d8082a1790fa40315": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e75b3f3bc954418794aae38440ea1b41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e29c22fa3b7241f2a21fbe59a5f11beb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4df7d3146c414792b57e4a496d87ce0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "837165be89064b4697f48cea3ef2c76d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_be299484af984ca6840496e83cbaf139",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b8baa2b21e2f4de29bcd3db23cea73c9",
              "IPY_MODEL_b44135fa7129457aaa704508273d4bfd"
            ]
          }
        },
        "be299484af984ca6840496e83cbaf139": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b8baa2b21e2f4de29bcd3db23cea73c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e02ea051b4da41cc8b67f81a51386464",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 150,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 150,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7c73590cdcb34cb5a1bbbf5a857852df"
          }
        },
        "b44135fa7129457aaa704508273d4bfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c34badbab6094758899e15ceeed6f44b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 150/150 [01:46&lt;00:00,  1.40it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6dd0f4555eb8438fac5bd60c2f9bb5a3"
          }
        },
        "e02ea051b4da41cc8b67f81a51386464": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7c73590cdcb34cb5a1bbbf5a857852df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c34badbab6094758899e15ceeed6f44b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6dd0f4555eb8438fac5bd60c2f9bb5a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pstanisl/mlprague-2021/blob/main/05_CMAB_movielens_linear_tf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ku9blLrybt_E"
      },
      "source": [
        "# Linear Contextual Multi-Armed Bandits \n",
        "\n",
        "From now we will use [TensorFlow Agents](https://www.tensorflow.org/agents), so so it's probably appropriate to say something about this library. Agents is a library for reinforcement learning in TensorFlow.  \n",
        "\n",
        "> TF-Agents makes designing, implementing, and testing new RL algorithms easier by providing well-tested modular components that can be modified and extended. It enables fast code iteration with good test integration and benchmarking.\n",
        "\n",
        "It provides API for creating all aspects necessary for reinforcement learning with Tensorflow, example of API can be seen below.\n",
        "\n",
        "```python\n",
        "import tensorflow as tf\n",
        "from tf_agents.networks import q_network\n",
        "from tf_agents.agents.dqn import dqn_agent\n",
        "\n",
        "q_net = q_network.QNetwork(\n",
        "  train_env.observation_spec(),\n",
        "  train_env.action_spec(),\n",
        "  fc_layer_params=(100,))\n",
        "\n",
        "agent = dqn_agent.DqnAgent(\n",
        "  train_env.time_step_spec(),\n",
        "  train_env.action_spec(),\n",
        "  q_network=q_net,\n",
        "  optimizer=optimizer,\n",
        "  td_errors_loss_fn=common.element_wise_squared_loss,\n",
        "  train_step_counter=tf.Variable(0))\n",
        "\n",
        "agent.initialize()\n",
        "```\n",
        "\n",
        "As Multi-Armed Bandits can be seen as a special case of RL, TF-Agents contains also building blocks for MAB, especially for Contextual Multi-Armed Bandits (CMAB). ☺️\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6fNTjpnu6eS"
      },
      "source": [
        "#### Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbVPxLuUR25T"
      },
      "source": [
        "!pip install tf-agents -q"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2MMqktAoX5e",
        "outputId": "98edce8a-76c4-4b3a-8910-819fef5d858c"
      },
      "source": [
        "!rm -f ./utils.py\n",
        "!wget --no-check-certificate --no-cache --no-cookies \\\n",
        "    https://raw.githubusercontent.com/pstanisl/mlprague-2021/main/utils.py \\\n",
        "    -O ./utils.py"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-26 10:24:24--  https://raw.githubusercontent.com/pstanisl/mlprague-2021/main/utils.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4941 (4.8K) [text/plain]\n",
            "Saving to: ‘./utils.py’\n",
            "\n",
            "\r./utils.py            0%[                    ]       0  --.-KB/s               \r./utils.py          100%[===================>]   4.83K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-02-26 10:24:24 (55.8 MB/s) - ‘./utils.py’ saved [4941/4941]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02ZZepbLdTS7"
      },
      "source": [
        "#### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUEquHXHRwwB"
      },
      "source": [
        "import functools\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf  # pylint: disable=g-explicit-tensorflow-version-import\n",
        "import tensorflow_probability as tfp\n",
        "import zipfile\n",
        "\n",
        "from tqdm.notebook import trange\n",
        "from typing import Optional, Sequence, Text, Tuple\n",
        "\n",
        "from tf_agents.agents import data_converter\n",
        "from tf_agents.agents import tf_agent\n",
        "from tf_agents.bandits.agents import linear_bandit_agent as lin_agent\n",
        "from tf_agents.bandits.agents import utils as bandit_utils\n",
        "from tf_agents.bandits.environments import environment_utilities\n",
        "from tf_agents.bandits.environments import bandit_py_environment\n",
        "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
        "from tf_agents.bandits.policies import linalg\n",
        "from tf_agents.bandits.policies import linear_bandit_policy\n",
        "from tf_agents.bandits.policies import policy_utilities\n",
        "from tf_agents.drivers import dynamic_step_driver\n",
        "from tf_agents.environments import tf_py_environment\n",
        "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
        "from tf_agents.policies import tf_policy\n",
        "from tf_agents.specs import array_spec\n",
        "from tf_agents.specs import tensor_spec\n",
        "from tf_agents.trajectories import policy_step\n",
        "from tf_agents.trajectories import time_step as ts\n",
        "from tf_agents.typing import types\n",
        "\n",
        "from utils import load_movielens_data, plot_regret, trajectory_for_bandit"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pQURB_g5EZB"
      },
      "source": [
        "class BannerEnvironment(bandit_py_environment.BanditPyEnvironment):\r\n",
        "\r\n",
        "  def __init__(self, ctrs: Sequence[float]):\r\n",
        "    action_spec = array_spec.BoundedArraySpec(\r\n",
        "        shape=(), dtype=np.int32, minimum=0, maximum=len(ctrs) - 1, name='action')\r\n",
        "    observation_spec = array_spec.BoundedArraySpec(\r\n",
        "        shape=(1,), dtype=np.float32, minimum=0., maximum=1., name='observation')\r\n",
        "    \r\n",
        "    self.ctrs = ctrs\r\n",
        "\r\n",
        "    super(BannerEnvironment, self).__init__(observation_spec, action_spec)\r\n",
        "\r\n",
        "  def _observe(self):\r\n",
        "    self._observation = np.random.rand(1)\r\n",
        "    return self._observation\r\n",
        "\r\n",
        "  def _apply_action(self, action):\r\n",
        "    return self.ctrs[action] > self._observation[0]\r\n",
        "\r\n",
        "\r\n",
        "class GreedyPolicy(tf_policy.TFPolicy):\r\n",
        "  def __init__(self, n, values):\r\n",
        "    action_spec = tensor_spec.BoundedTensorSpec(\r\n",
        "        shape=(), dtype=tf.int32, minimum=0, maximum=n - 1)\r\n",
        "    observation_spec = tensor_spec.BoundedTensorSpec(\r\n",
        "        shape=(1,), dtype=tf.float64, minimum=0., maximum=1)\r\n",
        "    time_step_spec = ts.time_step_spec(observation_spec)\r\n",
        "    \r\n",
        "    self._values = values\r\n",
        "\r\n",
        "    super(GreedyPolicy, self).__init__(\r\n",
        "        time_step_spec=time_step_spec, action_spec=action_spec)\r\n",
        "\r\n",
        "  def _variables(self) -> Sequence[tf.Variable]:\r\n",
        "    return []\r\n",
        "\r\n",
        "  def _action(\r\n",
        "      self, \r\n",
        "      time_step: ts.TimeStep, \r\n",
        "      policy_state: types.NestedTensor = (), \r\n",
        "      seed: Optional[types.Seed] = None) -> policy_step.PolicyStep:\r\n",
        "    action = tf.cast(tf.reshape(tf.math.argmax(self._values), [1]), dtype=tf.int32)\r\n",
        "    return policy_step.PolicyStep(action, policy_state)\r\n",
        "\r\n",
        "\r\n",
        "class GreedyAgent(tf_agent.TFAgent):\r\n",
        "  def __init__(self, n: int):\r\n",
        "    self._n = n\r\n",
        "    self._counts = tf.Variable(tf.zeros([n], dtype=tf.int32))\r\n",
        "    self._values = tf.Variable(tf.ones([n], dtype=tf.float32))\r\n",
        "\r\n",
        "    policy = GreedyPolicy(n, self._values)\r\n",
        "    time_step_spec = policy.time_step_spec\r\n",
        "    action_spec = policy.action_spec\r\n",
        "\r\n",
        "    super(GreedyAgent, self).__init__(\r\n",
        "        time_step_spec=time_step_spec,\r\n",
        "        action_spec=action_spec,\r\n",
        "        policy=policy,\r\n",
        "        collect_policy=policy,\r\n",
        "        train_sequence_length=None)\r\n",
        "\r\n",
        "  def _initialize(self) -> Optional[tf.Operation]:\r\n",
        "    return tf.compat.v1.variables_initializer(self.variables)\r\n",
        "\r\n",
        "  def _train(\r\n",
        "      self, \r\n",
        "      experience: types.NestedTensor, \r\n",
        "      weights: Optional[types.Tensor] = None) -> tf_agent.LossInfo:\r\n",
        "    # Get all necessary info from the trajectory\r\n",
        "    observation = experience.observation\r\n",
        "    action = experience.action\r\n",
        "    reward = experience.reward\r\n",
        "    \r\n",
        "    i = action.numpy()[0, 0]\r\n",
        "    c_update = np.zeros(self._n)\r\n",
        "    c_update[i] += 1\r\n",
        "\r\n",
        "    #self._counts = self._counts + c_update\r\n",
        "    tf.compat.v1.assign_add(self._counts, c_update)\r\n",
        "\r\n",
        "    values = self._values.numpy()\r\n",
        "    n = self._counts.numpy()[i]\r\n",
        "\r\n",
        "    values[i] = ((n - 1) / n) * values[i] + (1 / n) * reward.numpy()\r\n",
        "\r\n",
        "    tf.compat.v1.assign(self._values, values)\r\n",
        "\r\n",
        "    return tf_agent.LossInfo((), ())\r\n"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZ2zIGRd6hXi",
        "outputId": "888725e6-42ff-4082-dac0-de511120b09b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "environment = tf_py_environment.TFPyEnvironment(BannerEnvironment([0.25, 0.4, 0.67]))\r\n",
        "step = environment.reset()\r\n",
        "\r\n",
        "agent = GreedyAgent(3)\r\n",
        "\r\n",
        "for _ in range(100):\r\n",
        "  action_step = agent.collect_policy.action(step)  \r\n",
        "  next_step = environment.step(action_step.action)  \r\n",
        "  # Create trajectory nested \r\n",
        "  experience = trajectory_for_bandit(step, action_step, next_step)\r\n",
        "  # Train policy in the agent\r\n",
        "  agent.train(experience)\r\n",
        "  step = next_step\r\n",
        "\r\n",
        "print(f'Agent\\'s reward estimations={agent._values.numpy()} and counts={agent._counts.numpy()}')"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Agent's reward estimations=[0.        0.5       0.7010309] and counts=[ 1  2 97]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b47tWwUVdgbV"
      },
      "source": [
        "#### Downloading the [MovieLens](https://grouplens.org/datasets/movielens/) (100K) dataset.\n",
        "\n",
        "**Dataset info**\n",
        "\n",
        "MovieLens data sets were collected by the GroupLens Research Project\n",
        "at the University of Minnesota.\n",
        "\n",
        "This data set consists of:\n",
        "* 100,000 ratings (1-5) from 943 users on 1682 movies.\n",
        "* Each user has rated at least 20 movies.\n",
        "* Simple demographic info for the users (age, gender, occupation, zip)\n",
        "\n",
        "The data was collected through the MovieLens web site\n",
        "(movielens.umn.edu) during the seven-month period from September 19th,\n",
        "1997 through April 22nd, 1998. This data has been cleaned up - users\n",
        "who had less than 20 ratings or did not have complete demographic\n",
        "information were removed from this data set. Detailed descriptions of\n",
        "the data file can be found at the end of this file.\n",
        "\n",
        "Neither the University of Minnesota nor any of the researchers\n",
        "involved can guarantee the correctness of the data, its suitability\n",
        "for any particular purpose, or the validity of results based on the\n",
        "use of the data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8_xdGprnyqb",
        "outputId": "24aa0344-b26d-4c5b-c270-f63294a55a0a"
      },
      "source": [
        "print(\"Downloading movielens data...\")\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    http://files.grouplens.org/datasets/movielens/ml-100k.zip \\\n",
        "    -O ./movielens.zip\n",
        "\n",
        "zip_ref = zipfile.ZipFile('movielens.zip', \"r\")\n",
        "zip_ref.extractall()\n",
        "\n",
        "print(\"Done. Dataset contains:\")\n",
        "print(zip_ref.read('ml-100k/u.info').decode())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading movielens data...\n",
            "--2021-02-26 10:24:27--  http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4924029 (4.7M) [application/zip]\n",
            "Saving to: ‘./movielens.zip’\n",
            "\n",
            "./movielens.zip     100%[===================>]   4.70M  16.0MB/s    in 0.3s    \n",
            "\n",
            "2021-02-26 10:24:27 (16.0 MB/s) - ‘./movielens.zip’ saved [4924029/4924029]\n",
            "\n",
            "Done. Dataset contains:\n",
            "943 users\n",
            "1682 items\n",
            "100000 ratings\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBsEus-bdkRM"
      },
      "source": [
        "#### Parameters -- Feel Free to Play Around"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2Tf9d1NcbF9"
      },
      "source": [
        "RANK_K = 20 # @param {type:\"integer\"}\n",
        "NUM_ACTIONS = 20 # @param {type:\"integer\"}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvFAsPqLlmKQ"
      },
      "source": [
        "## Environment\n",
        "\n",
        "Implementation of the environment uses **MovieLens 100K dataset**. As described above, the dataset contains 100000 ratings from 943 users and 1682 movies. The environment can consider only the first $n$ of the dataset's movies. It can be set-up by `num_actions`. The number of \"known\" movies for the environment is equal to actions/arms.\n",
        "\n",
        "> Users without a rating (after selecting first $n$ movies) are removed from the environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW6QuzcKX8gq"
      },
      "source": [
        "class MovieLensPyEnvironment(bandit_py_environment.BanditPyEnvironment):\n",
        "  \"\"\"Implements the MovieLens Bandit environment.\n",
        "  This environment implements the MovieLens 100K dataset, available at:\n",
        "  https://www.kaggle.com/prajitdatta/movielens-100k-dataset\n",
        "  This dataset contains 100K ratings from 943 users on 1682 items.\n",
        "  This csv list of:\n",
        "  user id | item id | rating | timestamp.\n",
        "  This environment computes a low-rank matrix factorization (using SVD) of the\n",
        "  data matrix A, such that: A ~= U * V.\n",
        "  The reward of recommending item `j` to user `i` is provided as A_{ij}.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               data_dir: Text,\n",
        "               rank_k: int,\n",
        "               batch_size: int = 1,\n",
        "               num_movies: int = 20,\n",
        "               name: Optional[Text] = 'movielens'):\n",
        "    \"\"\"Initializes the MovieLens Bandit environment.\n",
        "    Args:\n",
        "      data_dir: (string) Directory where the data lies (in text form).\n",
        "      rank_k : (int) Which rank to use in the matrix factorization.\n",
        "      batch_size: (int) Number of observations generated per call.\n",
        "      num_movies: (int) Only the first `num_movies` movies will be used by the\n",
        "        environment. The rest is cut out from the data.\n",
        "      name: The name of this environment instance.\n",
        "    \"\"\"\n",
        "    self._num_actions = num_movies\n",
        "    self._batch_size = batch_size\n",
        "    self._context_dim = rank_k\n",
        "\n",
        "    # Compute the matrix factorization.\n",
        "    #self._data_matrix = dataset_utilities.load_movielens_data(data_dir)\n",
        "    self._data_matrix = load_movielens_data(data_dir)\n",
        "    # Keep only the first items.\n",
        "    self._data_matrix = self._data_matrix[:, :num_movies]\n",
        "    # Filter the users with no iterm rated.\n",
        "    nonzero_users = list(np.nonzero(np.sum(self._data_matrix, axis=1) > 0.0)[0])\n",
        "    self._data_matrix = self._data_matrix[nonzero_users, :]\n",
        "    self._effective_num_users = len(nonzero_users)\n",
        "\n",
        "    # Compute the SVD.\n",
        "    u, s, vh = np.linalg.svd(self._data_matrix, full_matrices=False)\n",
        "\n",
        "    # Keep only the largest singular values.\n",
        "    self._u_hat = u[:, :rank_k] * np.sqrt(s[:rank_k])\n",
        "    self._v_hat = np.transpose(\n",
        "        np.transpose(vh[:rank_k, :]) * np.sqrt(s[:rank_k]))\n",
        "    self._approx_ratings_matrix = np.matmul(self._u_hat, self._v_hat)\n",
        "\n",
        "    self._current_users = np.zeros(batch_size, dtype=np.int32)\n",
        "    self._previous_users = np.zeros(batch_size, dtype=np.int32)\n",
        "\n",
        "    self._action_spec = array_spec.BoundedArraySpec(\n",
        "        shape=(),\n",
        "        dtype=np.int32,\n",
        "        minimum=0,\n",
        "        maximum=self._num_actions - 1,\n",
        "        name='action')\n",
        "    observation_spec = array_spec.ArraySpec(\n",
        "        shape=(self._context_dim,), dtype=np.float64, name='observation')\n",
        "    self._time_step_spec = ts.time_step_spec(observation_spec)\n",
        "    self._observation = np.zeros((self._batch_size, self._context_dim))\n",
        "\n",
        "    self._optimal_action_table = np.argmax(\n",
        "        self._approx_ratings_matrix, axis=1)\n",
        "    self._optimal_reward_table = np.max(\n",
        "        self._approx_ratings_matrix, axis=1)\n",
        "\n",
        "    super(MovieLensPyEnvironment, self).__init__(\n",
        "        observation_spec, self._action_spec)\n",
        "\n",
        "  @property\n",
        "  def batch_size(self):\n",
        "    return self._batch_size\n",
        "\n",
        "  @property\n",
        "  def batched(self):\n",
        "    return True\n",
        "\n",
        "  def _observe(self):\n",
        "    \"\"\"Returns the u vectors of a random sample of users.\"\"\"\n",
        "    sampled_users = random.sample(\n",
        "        range(self._effective_num_users), self._batch_size)\n",
        "    self._previous_users = self._current_users\n",
        "    self._current_users = sampled_users\n",
        "    batched_observations = self._u_hat[sampled_users]\n",
        "    return batched_observations\n",
        "\n",
        "  def _apply_action(self, action):\n",
        "    \"\"\"Computes the reward for the input actions.\"\"\"\n",
        "    rewards = []\n",
        "    for i, j in zip(self._current_users, action):\n",
        "      rewards.append(self._approx_ratings_matrix[i, j])\n",
        "    return np.array(rewards)\n",
        "\n",
        "  def compute_optimal_action(self):\n",
        "    return self._optimal_action_table[self._previous_users]\n",
        "\n",
        "  def compute_optimal_reward(self):\n",
        "    return self._optimal_reward_table[self._previous_users]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rxo7RipFdrPk"
      },
      "source": [
        "Now we are equipped to initialize our environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWLNxLEiT05z"
      },
      "source": [
        "env = MovieLensPyEnvironment('./ml-100k/u.data', RANK_K, 1, num_movies=NUM_ACTIONS)\n",
        "tf_env = tf_py_environment.TFPyEnvironment(env)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4IcbZr5duJt"
      },
      "source": [
        "Below we can check what this environment produces."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcRZbsaSUCEh",
        "outputId": "7cff74fd-d118-4dfb-bb95-cfd91ece77ee"
      },
      "source": [
        "print('Observation spec:', tf_env.observation_spec())\n",
        "print('An observation: ', tf_env.reset().observation.numpy())\n",
        "\n",
        "action = tf.zeros(1, dtype=tf.int32)\n",
        "time_step = tf_env.step(action)\n",
        "\n",
        "print(f'For users={env._previous_users}, we selected action={action.numpy()} (optimal={tf_env.compute_optimal_action()})')\n",
        "print(f'For users={env._previous_users}, we received reward={time_step.reward.numpy()} (optimal={tf_env.compute_optimal_reward()})')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Observation spec: TensorSpec(shape=(20,), dtype=tf.float64, name='observation')\n",
            "An observation:  [[-0.34334335  0.11788707 -0.29889088  0.45522508  0.34703715 -0.14089986\n",
            "  -0.07600747 -0.2103988   0.16195312  0.22695256  0.02028607  0.2660434\n",
            "  -0.21456528  0.16732334  0.03560834  0.01823502 -0.01180787  0.00209479\n",
            "  -0.0546743  -0.01131993]]\n",
            "For users=[301], we selected action=[0] (optimal=[0])\n",
            "For users=[301], we received reward=[4.] (optimal=[4.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTjTE8ThV85o"
      },
      "source": [
        "## Policy - LinerUCB\n",
        "\n",
        "As we leant in UCB example, the Upper Confidence Bounds (UCB) algorithm measures potential by an upper confidence bound of the reward value, $\\hat{U}_{t}(a)$, so that the true value is below with bound $Q(a) \\leq \\hat{Q}_t(a) + \\hat{U}_t(a)$ with high probability. The upper bound $\\hat{U}_t(a)$ is a function of $N_t(a)$; a larger number of trials $N_t(a)$ should give us a smaller bound $\\hat{U}_t(a)$, see picture below.\n",
        "\n",
        "<center>\n",
        "  <img src=\"https://miro.medium.com/max/4800/1*p_4mvZ6r6ddbShd7tOT0sw.png\" alt=\"source: https://towardsdatascience.com/recommender-systems-using-linucb-a-contextual-multi-armed-bandit-approach-35a6f0eb6c4\" width=\"600\"/>\n",
        "</center>\n",
        "\n",
        "<!--![](https://miro.medium.com/max/4800/1*p_4mvZ6r6ddbShd7tOT0sw.png \"source: https://towardsdatascience.com/recommender-systems-using-linucb-a-contextual-multi-armed-bandit-approach-35a6f0eb6c4\")-->\n",
        "\n",
        "For contextual bandits UCB, the expected payoff of an action is assumed to be linear in its d-dimensional feature vector $X$ with some unknown coefficient vector $\\theta$.\n",
        "\n",
        "$$\n",
        "E\\left[r_{t,a}|x_{t,a}\\right] = x^{T}_{t,a}\\theta^{\\ast}_{a}\n",
        "$$\n",
        "\n",
        "An upper confidence bound has to be calculated for each action for the algorithm to be able to choose an arm at every trial. The strategy for choosing the action at every trial $t$ is formalised as\n",
        "\n",
        "$$\n",
        "a_{t} \\stackrel{def}{=} argmax\\left(x^{T}_{t,a}\\hat{\\theta}_{a} + \\alpha \\sqrt{x^{T}_{t,a} A^{-1} x_{t,a}} \\right),\n",
        "$$\n",
        "\n",
        "where $\\hat{\\theta} = A^{-1}b$.\n",
        "\n",
        "<br/>\n",
        "\n",
        "**TASK**: Fill in the missing pieces of code and create:\n",
        "\n",
        "1. computation of the confidence intervals,\n",
        "1. choosing the next action."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10eDwxGDV-n6"
      },
      "source": [
        "class LinearUCBPolicy(linear_bandit_policy.LinearBanditPolicy):\n",
        "  \"\"\"LinearUCB policy is simplified version of LinearBanditPolicy from tf_agente.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               action_spec: types.BoundedTensorSpec,\n",
        "               variable_collection: tf.Module,\n",
        "               time_step_spec: Optional[types.TimeStep] = None,\n",
        "               alpha: float = 1.0,\n",
        "               tikhonov_weight: float = 1.0,\n",
        "               name: Optional[Text] = None):\n",
        "    super(LinearUCBPolicy, self).__init__(\n",
        "        action_spec,\n",
        "        cov_matrix=variable_collection.cov_matrix_list,\n",
        "        data_vector=variable_collection.data_vector_list,\n",
        "        num_samples=variable_collection.num_samples_list,\n",
        "        time_step_spec=time_step_spec,\n",
        "        alpha=alpha,\n",
        "        tikhonov_weight=tikhonov_weight,\n",
        "        name=name)\n",
        "\n",
        "  def _distribution(self, time_step, policy_state):\n",
        "    observation = tf.nest.map_structure(lambda o: tf.cast(o, dtype=self._dtype),\n",
        "                                        time_step.observation)\n",
        "    \n",
        "    current_observation = tf.reshape(\n",
        "        observation, [-1, self._global_context_dim])\n",
        "\n",
        "    est_rewards = []\n",
        "    confidence_intervals = []\n",
        "\n",
        "    for model_index in range(self._num_actions):\n",
        "      a = self._cov_matrix[model_index]\n",
        "      b = self._data_vector[model_index]\n",
        "      # Compute confidence interval for action(i): x^T*A^-1*x\n",
        "      # 1: A^-1*x -> A^-1x - A = a + tikhonow * I\n",
        "      a_inv_x = linalg.conjugate_gradient_solve(\n",
        "          a + self._tikhonov_weight *\n",
        "          tf.eye(self._overall_context_dim, dtype=self._dtype),\n",
        "          tf.linalg.matrix_transpose(current_observation)) # YOUR CODE HERE\n",
        "      # 2: x^T*A^-1x -> confidence interval of action(i)\n",
        "      ci = tf.reshape(\n",
        "          tf.linalg.tensor_diag_part(tf.matmul(current_observation, a_inv_x)), # YOUR CODE HERE\n",
        "          [-1, 1])\n",
        "      \n",
        "      confidence_intervals.append(ci)\n",
        "      est_mean_reward = tf.einsum('j,jk->k', b,\n",
        "                                  a_inv_x)\n",
        "      est_rewards.append(est_mean_reward)\n",
        "    # Estimate rewards for every action\n",
        "    optimistic_estimates = [\n",
        "        tf.reshape(mean_reward, [-1, 1]) + self._alpha * tf.sqrt(confidence)\n",
        "        for mean_reward, confidence in zip(est_rewards, confidence_intervals)\n",
        "    ]\n",
        "    # Keeping the batch dimension during the squeeze, even if batch_size == 1.\n",
        "    rewards_for_argmax = tf.squeeze(\n",
        "        tf.stack(optimistic_estimates, axis=-1), axis=[1])\n",
        "    \n",
        "    # Choose the best action for every observation in the batch\n",
        "    chosen_actions = tf.argmax(\n",
        "        rewards_for_argmax, # YOUR CODE HERE\n",
        "        axis=-1,\n",
        "        output_type=tf.nest.flatten(self._action_spec)[0].dtype)\n",
        "\n",
        "    action_distributions = tfp.distributions.Deterministic(loc=chosen_actions)\n",
        "\n",
        "    policy_info = policy_utilities.populate_policy_info(\n",
        "        None, chosen_actions, rewards_for_argmax,\n",
        "        tf.stack(est_rewards, axis=-1), self._emit_policy_info,\n",
        "        False)\n",
        "\n",
        "    return policy_step.PolicyStep(\n",
        "        action_distributions, policy_state, policy_info)\n",
        "    "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uo3YPdpkxYsr"
      },
      "source": [
        "## Agent\n",
        "\n",
        "For contextual bandits UCB, the expected payoff of an action is assumed to be linear in its d-dimensional feature vector $X$ with some unknown coefficient vector $\\theta$.\n",
        "\n",
        "$$\n",
        "E\\left[r_{t,a}|x_{t,a}\\right] = x^{T}_{t,a}\\theta^{\\ast}_{a}\n",
        "$$\n",
        "\n",
        "This model is called disjoint since the parameters are not shared among different actions/arms. To solve for the coefficient vector $\\theta$ in the above equation ridge regression ([Tikhonov regularization](https://en.wikipedia.org/wiki/Tikhonov_regularization)) is applied to the training data. The whole algorithm is described below\n",
        "\n",
        "<center>\n",
        "  <img src=\"https://raw.githubusercontent.com/pstanisl/mlprague-2021/main/img/linucb_algorithm.png\" alt=\"LinUCB algorithm\" width=\"400\"/>\n",
        "</center>\n",
        "\n",
        "<!--![linucb_algorithm.png](https://raw.githubusercontent.com/pstanisl/mlprague-2021/main/img/linucb_algorithm.png =100x)-->\n",
        "\n",
        "> More details about the algorithm can be found in the [A contextual-bandit approach to\n",
        "personalized news article recommendation](https://arxiv.org/pdf/1003.0146.pdf) and [Linear Upper Confidence Bound Algorithm for Contextual Bandit Problem with Piled Rewards](https://khhuang.me/docs/pakdd2016linucbpr.pdf) papers.\n",
        "\n",
        "The LinearAgent with `LinearUCBPolicy` agent implements the identically named Bandit algorithm, which estimates the parameter of the linear reward function while also maintains a confidence ellipsoid around the estimate. The agent chooses the action/arm that has the highest estimated expected reward, assuming that the parameter lies within the confidence ellipsoid."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2zoC7YYVzxj"
      },
      "source": [
        "def sum_reward_weighted_observations(r: types.Tensor,\n",
        "                                     x: types.Tensor) -> types.Tensor:\n",
        "  \"\"\"Calculates an update used by some Bandit algorithms.\n",
        "  Given an observation `x` and corresponding reward `r`, the weigthed\n",
        "  observations vector (denoted `b` here) should be updated as `b = b + r * x`.\n",
        "  This function calculates the sum of weighted rewards for batched\n",
        "  observations `x`.\n",
        "\n",
        "  Args:\n",
        "    r: a `Tensor` of shape [`batch_size`]. This is the rewards of the batched\n",
        "      observations.\n",
        "    x: a `Tensor` of shape [`batch_size`, `context_dim`]. This is the matrix\n",
        "      with the (batched) observations.\n",
        "      \n",
        "  Returns:\n",
        "    The update that needs to be added to `b`. Has the same shape as `b`.\n",
        "    If the observation matrix `x` is empty, a zero vector is returned.\n",
        "  \"\"\"\n",
        "  batch_size = tf.shape(x)[0]\n",
        "\n",
        "  return tf.reduce_sum(tf.reshape(r, [batch_size, 1]) * x, axis=0)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMo6hdUpD6hO"
      },
      "source": [
        "class LinearAgent(lin_agent.LinearBanditAgent):\n",
        "  \"\"\"Simplified implentation of an agent that maintains linear reward \n",
        "  estimates and their uncertainties.\n",
        "  \n",
        "  Original implementation can be found here: http://bit.ly/3kk7v3D\n",
        "  \"\"\"\n",
        "  def __init__(self,\n",
        "              time_step_spec: types.TimeStep,\n",
        "              action_spec: types.BoundedTensorSpec,\n",
        "              policy_class: linear_bandit_policy.LinearBanditPolicy = LinearUCBPolicy,\n",
        "              alpha: float = 1.0,\n",
        "              tikhonov_weight: float = 1.0,\n",
        "              dtype: tf.DType = tf.float32,\n",
        "              name: Optional[Text] = None):\n",
        "\n",
        "    super(LinearAgent, self).__init__(\n",
        "        lin_agent.ExplorationPolicy.linear_ucb_policy,\n",
        "        time_step_spec=time_step_spec,\n",
        "        action_spec=action_spec,\n",
        "        alpha=alpha,\n",
        "        tikhonov_weight=tikhonov_weight,\n",
        "        dtype=dtype,\n",
        "        name=name\n",
        "    )\n",
        "\n",
        "    self._as_trajectory = data_converter.AsTrajectory(\n",
        "      self.data_context, sequence_length=None)\n",
        "\n",
        "    self._policy = self._policy = policy_class(\n",
        "        action_spec=action_spec,\n",
        "        variable_collection=self._variable_collection,\n",
        "        time_step_spec=time_step_spec,\n",
        "        alpha=alpha,\n",
        "        tikhonov_weight=tikhonov_weight\n",
        "    )\n",
        "  \n",
        "  def _train(self, experience, weights=None):\n",
        "    \"\"\"Updates the policy based on the data in `experience`.\n",
        "    Note that `experience` should only contain data points that this agent has\n",
        "    not previously seen. If `experience` comes from a replay buffer, this buffer\n",
        "    should be cleared between each call to `train`.\n",
        "    Args:\n",
        "      experience: A batch of experience data in the form of a `Trajectory`.\n",
        "      weights: Unused.\n",
        "    Returns:\n",
        "        A `LossInfo` containing the loss *before* the training step is taken.\n",
        "        In most cases, if `weights` is provided, the entries of this tuple will\n",
        "        have been calculated with the weights.  Note that each Agent chooses\n",
        "        its own method of applying weights.\n",
        "    \"\"\"\n",
        "    experience = self._as_trajectory(experience)\n",
        "\n",
        "    del weights  # unused\n",
        "\n",
        "    reward, action, observation, batch_size = self._process_experience(\n",
        "        experience)\n",
        "    \n",
        "    for k in range(self._num_models):\n",
        "      # Create identity matrix used as a mask\n",
        "      diag_mask = tf.linalg.tensor_diag(\n",
        "          tf.cast(tf.equal(action, k), self._dtype))\n",
        "      # Get an observation for the action from the observation\n",
        "      observations_for_arm = tf.matmul(diag_mask, observation)\n",
        "      rewards_for_arm = tf.matmul(diag_mask, tf.reshape(reward, [-1, 1]))\n",
        "      num_samples_for_arm_current = tf.reduce_sum(diag_mask)\n",
        "      \n",
        "      tf.compat.v1.assign_add(self._num_samples_list[k],\n",
        "                              num_samples_for_arm_current)\n",
        "      num_samples_for_arm_total = self._num_samples_list[k].read_value()\n",
        "\n",
        "      # Update the covariance matrix `a` and the weighted sum of rewards `b`\n",
        "      # using a forgetting factor `gamma`.\n",
        "      \n",
        "      # YOUR CODE GOES HERE\n",
        "      x = observations_for_arm\n",
        "      r = rewards_for_arm\n",
        "      a_prev = self._cov_matrix_list[k]\n",
        "      b_prev = self._data_vector_list[k]\n",
        "\n",
        "      a_new = self._gamma * a_prev + tf.matmul(x, x, transpose_a=True)\n",
        "      b_new = self._gamma * b_prev + sum_reward_weighted_observations(r, x)\n",
        "      # END OF YOUR CODE\n",
        "\n",
        "      # Update real variables\n",
        "      tf.compat.v1.assign(self._cov_matrix_list[k], a_new) # YOUR CODE HERE\n",
        "      tf.compat.v1.assign(self._data_vector_list[k], b_new) # YOUR CODE HERE\n",
        "\n",
        "    loss = -1. * tf.reduce_sum(reward) # YOUR CODE HERE\n",
        "    self.compute_summaries(loss)\n",
        "\n",
        "    self._train_step_counter.assign_add(batch_size)\n",
        "\n",
        "    return tf_agent.LossInfo(loss=(loss), extra=())"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Huc03djLkNyt"
      },
      "source": [
        "Helper function for creating an instance of the `LinearAgent` with a linear policy like our `LinearUCBPolicy`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkJm2_WpgfaL"
      },
      "source": [
        "def get_agent(\n",
        "    environment, \n",
        "    policy_class: linear_bandit_policy.LinearBanditPolicy = LinearUCBPolicy,\n",
        "    tikhonov_weight: float = 0.001, \n",
        "    alpha: float = 10.0\n",
        "):  \n",
        "  return LinearAgent(\n",
        "    time_step_spec=environment.time_step_spec(),\n",
        "    action_spec=environment.action_spec(),\n",
        "    policy_class=policy_class,\n",
        "    tikhonov_weight=tikhonov_weight,\n",
        "    alpha=alpha,\n",
        "    dtype=tf.float32\n",
        "  )"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bG8LVv2rW1sK"
      },
      "source": [
        "agent = get_agent(\n",
        "    tf_env, policy_class=LinearUCBPolicy, tikhonov_weight=0.001, alpha=10.0)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nE2kDQ2kcSo"
      },
      "source": [
        "Let have a look at the data specification in the agent. The `training_data_spec` attribute of the agent specifies what elements and structure the training data should have. The `training_data_spec.observation` specificate the structure of the context vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPg7h-hIlTnx",
        "outputId": "6ab089a5-2894-40ca-c0a6-0f017b79dc5c"
      },
      "source": [
        "print('training data spec: ', agent.training_data_spec)\n",
        "print('observation spec in training: ', agent.training_data_spec.observation)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training data spec:  Trajectory(step_type=TensorSpec(shape=(), dtype=tf.int32, name='step_type'), observation=TensorSpec(shape=(20,), dtype=tf.float64, name='observation'), action=BoundedTensorSpec(shape=(), dtype=tf.int32, name='action', minimum=array(0, dtype=int32), maximum=array(19, dtype=int32)), policy_info=PolicyInfo(log_probability=(), predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=()), next_step_type=TensorSpec(shape=(), dtype=tf.int32, name='step_type'), reward=TensorSpec(shape=(), dtype=tf.float32, name='reward'), discount=BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)))\n",
            "observation spec in training:  TensorSpec(shape=(20,), dtype=tf.float64, name='observation')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDjYCtBUl2j4"
      },
      "source": [
        "## Training\n",
        "\n",
        "Now we put together all the components that we introduced above: the environment, the policy, and the agent. We run the policy on the environment and output training data with the help of a driver, and train the agent on the data.\n",
        "\n",
        "#### Metrics\n",
        "\n",
        "Important of the training are metrics. If you read some materials you can find, that bandits' most important metric is regret, calculated as the difference between the reward collected by the agent and the expected reward of an oracle policy that has access to the reward functions of the environment. The [RegretMetric](https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/metrics/tf_metrics.py) thus needs a `baseline_reward_fn` function that calculates the best achievable expected reward given an observation. In our example, the optimal reward is computed in the `MovieLensPyEnvironment.compute_optimal_reward` from the approximation of the rating.\n",
        "\n",
        "> In reality, we usually do not have access to an oracle policy, so the regret is hard to get. Thus, the cumulative reward or other metric is often used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTmTQNtQpk_a"
      },
      "source": [
        "def get_metrics(environment):\n",
        "  optimal_reward_fn = functools.partial(\n",
        "        environment_utilities.compute_optimal_reward_with_movielens_environment,\n",
        "        environment=tf_env)\n",
        "  optimal_action_fn = functools.partial(\n",
        "        environment_utilities.compute_optimal_action_with_movielens_environment,\n",
        "        environment=tf_env)\n",
        "  \n",
        "  regret_metric = tf_bandit_metrics.RegretMetric(\n",
        "      optimal_reward_fn, \n",
        "      name='regret'\n",
        "  )\n",
        "  suboptimal_arms_metric = tf_bandit_metrics.SuboptimalArmsMetric(\n",
        "      optimal_action_fn,\n",
        "      name='suboptimal_arms'\n",
        "  )\n",
        "  \n",
        "  return [regret_metric, suboptimal_arms_metric]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7zx1AUBe5_f"
      },
      "source": [
        "We will put it all together in `run` function to run the training loop of our implementation of bandits' movie recommendations. The driver below is a helper object and takes care of choosing actions using the policy, storing rewards of chosen actions in the replay buffer, calculating the predefined regret metric, and executing the agent's training step. You can find more info about the driver [here](https://www.tensorflow.org/agents/tutorials/4_drivers_tutorial)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5foepaVcv9Y"
      },
      "source": [
        "def run(\n",
        "    environment, \n",
        "    agent, \n",
        "    iterations, \n",
        "    steps_per_loop,\n",
        "    additional_metrics=()\n",
        "):\n",
        "  replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
        "      data_spec=agent.policy.trajectory_spec,\n",
        "      batch_size=environment.batch_size,\n",
        "      max_length=steps_per_loop)\n",
        "  \n",
        "  metrics = [] + list(additional_metrics)\n",
        "  ret_metrics = dict([(m.name, []) for m in metrics])\n",
        "\n",
        "  observers = [replay_buffer.add_batch] + metrics\n",
        "\n",
        "  driver = dynamic_step_driver.DynamicStepDriver(\n",
        "      env=environment,\n",
        "      policy=agent.collect_policy,\n",
        "      num_steps=steps_per_loop * environment.batch_size,\n",
        "      observers=observers)\n",
        "\n",
        "  regret_values = []\n",
        "\n",
        "  for _ in trange(num_iterations):\n",
        "    driver.run()\n",
        "    loss_info = agent.train(replay_buffer.gather_all())\n",
        "    replay_buffer.clear()\n",
        "    # Log metrics value\n",
        "    for metric in metrics:\n",
        "      ret_metrics[metric.name].append(metric.result())\n",
        "\n",
        "  return ret_metrics"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7gENChle_nn"
      },
      "source": [
        "Down below is the code for creating all necessary instances. Note that two parameters together specify the number of steps taken. `num_iterations` specifies how many times we run the trainer loop, while the driver will take `steps_per_loop` steps per iteration. The main reason behind keeping both of these parameters is that some operations are done per iteration, while the driver does some in every step. For example, the agent's train function is only called once per iteration. The trade-off here is that if we train more often, our policy is \"fresher\"; on the other hand, training in bigger batches might be more time-efficient. `batch_size` defines how many actions are generated through one step. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271,
          "referenced_widgets": [
            "18f1a3fdfd4e4514b4ec95deae262f0d",
            "cee2c23e4b084b08a6064309064cb9b5",
            "36138681401a4f44adfcee98f32bdd5b",
            "405234c3e9634d1ea9d85caf0a631b8e",
            "184c97e9990d4a0d8082a1790fa40315",
            "e75b3f3bc954418794aae38440ea1b41",
            "e29c22fa3b7241f2a21fbe59a5f11beb",
            "4df7d3146c414792b57e4a496d87ce0b"
          ]
        },
        "id": "9yxB1q29LqWV",
        "outputId": "d360f360-2d10-40ab-94e5-2c6eb6e66297"
      },
      "source": [
        "batch_size =   32# @param {type:\"integer\"}\n",
        "num_iterations =   150# @param {type:\"integer\"}\n",
        "steps_per_loop =   2# @param {type:\"integer\"}\n",
        "agent_alpha = 2.0  # @param {type: \"number\"}\n",
        "tikhonov_weight = 0.001  # @param {type: \"number\"}\n",
        "\n",
        "env = MovieLensPyEnvironment(\n",
        "    './ml-100k/u.data', \n",
        "    rank_k=RANK_K,\n",
        "    batch_size=batch_size, \n",
        "    num_movies=NUM_ACTIONS\n",
        ")\n",
        "tf_env = tf_py_environment.TFPyEnvironment(env)\n",
        "tf_env.reset()\n",
        "\n",
        "agent = get_agent(\n",
        "    tf_env,\n",
        "    policy_class=LinearUCBPolicy,\n",
        "    tikhonov_weight=tikhonov_weight,\n",
        "    alpha=agent_alpha\n",
        ")\n",
        "\n",
        "additional_metrics = get_metrics(tf_env)\n",
        "\n",
        "metrics = run(\n",
        "    tf_env, \n",
        "    agent, \n",
        "    iterations=num_iterations,\n",
        "    steps_per_loop=steps_per_loop,\n",
        "    additional_metrics=additional_metrics\n",
        ")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "18f1a3fdfd4e4514b4ec95deae262f0d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=150.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tf_agents/drivers/dynamic_step_driver.py:203: calling while_loop_v2 (from tensorflow.python.ops.control_flow_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.while_loop(c, b, vars, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.while_loop(c, b, vars))\n",
            "WARNING:tensorflow:From <ipython-input-16-f0fa4f3e72bf>:28: ReplayBuffer.gather_all (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `as_dataset(..., single_deterministic_pass=True)` instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtoJvh6xeBxu"
      },
      "source": [
        "Now let's see the result. After running the last code snippet, the resulting plot (hopefully) shows that the average regret is going down as the agent is trained and the policy gets better in figuring out what the right action is, given the observation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "id": "jqo41BBZXLZh",
        "outputId": "a0f7d38e-f38b-4e78-e119-278ca7a3af11"
      },
      "source": [
        "plot_regret(metrics['regret'], {'algorithm': 'LinUCB'})"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Rc93uPhd5I1"
      },
      "source": [
        "## Linear Thomson Sampling policy\n",
        "\n",
        "<center>\n",
        "  <img src=\"https://raw.githubusercontent.com/pstanisl/mlprague-2021/main/img/lints_algorithm.png\" alt=\"LinTS algorithm\" width=\"400\"/>\n",
        "</center>\n",
        "\n",
        "> A detailed explanation for the two above cases can be found in the paper\n",
        "[\"Thompson Sampling for Contextual Bandits with Linear Payoffs\"](http://proceedings.mlr.press/v28/agrawal13.pdf),\n",
        "Shipra Agrawal, Navin Goyal, ICML 2013\n",
        ", and its [supplementary material](http://proceedings.mlr.press/v28/agrawal13-supp.pdf)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKxJtkHrwTaS"
      },
      "source": [
        "class LinearTSPolicy(linear_bandit_policy.LinearBanditPolicy):\n",
        "  \"\"\"LinearTS policy is simplified version of LinearBanditPolicy from tf_agents.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               action_spec: types.BoundedTensorSpec,\n",
        "               variable_collection: tf.Module,\n",
        "               time_step_spec: Optional[types.TimeStep] = None,\n",
        "               alpha: float = 1.0,\n",
        "               tikhonov_weight: float = 1.0,\n",
        "               name: Optional[Text] = None):\n",
        "    super(LinearTSPolicy, self).__init__(\n",
        "        action_spec,\n",
        "        cov_matrix=variable_collection.cov_matrix_list,\n",
        "        data_vector=variable_collection.data_vector_list,\n",
        "        num_samples=variable_collection.num_samples_list,\n",
        "        time_step_spec=time_step_spec,\n",
        "        alpha=alpha,\n",
        "        tikhonov_weight=tikhonov_weight,\n",
        "        name=name)\n",
        "\n",
        "  def _distribution(self, time_step, policy_state):\n",
        "    observation = tf.nest.map_structure(lambda o: tf.cast(o, dtype=self._dtype),\n",
        "                                        time_step.observation)\n",
        "    \n",
        "    current_observation = tf.reshape(\n",
        "        observation, [-1, self._global_context_dim])\n",
        "\n",
        "    est_rewards = []\n",
        "    confidence_intervals = []\n",
        "\n",
        "    for model_index in range(self._num_actions):\n",
        "      # Compute confidence interval for action(i): x^T*A^-1*x\n",
        "      # YOUR CODE GOES HERE\n",
        "      # 1: A^-1*x -> A^-1x\n",
        "      a_inv_x = linalg.conjugate_gradient_solve(\n",
        "          self._cov_matrix[model_index] + self._tikhonov_weight *\n",
        "          tf.eye(self._overall_context_dim, dtype=self._dtype),\n",
        "          tf.linalg.matrix_transpose(current_observation))\n",
        "      # 2: x^T*A^-1x -> confidence interval of action(i)\n",
        "      ci = tf.reshape(\n",
        "          tf.linalg.tensor_diag_part(tf.matmul(current_observation, a_inv_x)),\n",
        "          [-1, 1])\n",
        "      # END OF YOUR CODE\n",
        "      \n",
        "      confidence_intervals.append(ci)\n",
        "      est_mean_reward = tf.einsum('j,jk->k', self._data_vector[model_index],\n",
        "                                  a_inv_x)\n",
        "      est_rewards.append(est_mean_reward)\n",
        "    # Sample from the Normapl distribution\n",
        "    mu_sampler = tfp.distributions.Normal(\n",
        "          loc=tf.stack(est_rewards, axis=-1), # YOUR CODE HERE\n",
        "          scale=self._alpha *\n",
        "          tf.sqrt(tf.squeeze(tf.stack(confidence_intervals, axis=-1), axis=1))) # YOUR CODE HERE\n",
        "    rewards_for_argmax = mu_sampler.sample()\n",
        "    # Choose the best action for every observation in the batch\n",
        "    chosen_actions = tf.argmax(\n",
        "        rewards_for_argmax, # YOUR CODE HERE\n",
        "        axis=-1,\n",
        "        output_type=tf.nest.flatten(self._action_spec)[0].dtype)\n",
        "\n",
        "    action_distributions = tfp.distributions.Deterministic(loc=chosen_actions)\n",
        "\n",
        "    policy_info = policy_utilities.populate_policy_info(\n",
        "        None, chosen_actions, rewards_for_argmax,\n",
        "        tf.stack(est_rewards, axis=-1), self._emit_policy_info,\n",
        "        False)\n",
        "\n",
        "    return policy_step.PolicyStep(\n",
        "        action_distributions, policy_state, policy_info)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltBIXUg9mI7u"
      },
      "source": [
        "Let's repeat the training with `LinearTSPolicy` and see the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYdibk130cGM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "837165be89064b4697f48cea3ef2c76d",
            "be299484af984ca6840496e83cbaf139",
            "b8baa2b21e2f4de29bcd3db23cea73c9",
            "b44135fa7129457aaa704508273d4bfd",
            "e02ea051b4da41cc8b67f81a51386464",
            "7c73590cdcb34cb5a1bbbf5a857852df",
            "c34badbab6094758899e15ceeed6f44b",
            "6dd0f4555eb8438fac5bd60c2f9bb5a3"
          ]
        },
        "outputId": "dff6bb5b-eb2c-48e2-83f2-5fe5e8b73022"
      },
      "source": [
        "batch_size =    32# @param {type:\"integer\"}\n",
        "num_iterations =   150# @param {type:\"integer\"}\n",
        "steps_per_loop =   2# @param {type:\"integer\"}\n",
        "agent_alpha = 2.0  # @param {type: \"number\"}\n",
        "tikhonov_weight = 0.001  # @param {type: \"number\"}\n",
        "\n",
        "tf_env.reset()\n",
        "\n",
        "agent = get_agent(\n",
        "  tf_env,\n",
        "  policy_class=LinearTSPolicy,\n",
        "  tikhonov_weight=tikhonov_weight,\n",
        "  alpha=agent_alpha\n",
        ")\n",
        "\n",
        "additional_metrics = get_metrics(tf_env)\n",
        "\n",
        "metrics = run(\n",
        "  tf_env, \n",
        "  agent, \n",
        "  iterations=num_iterations,\n",
        "  steps_per_loop=steps_per_loop,\n",
        "  additional_metrics=additional_metrics\n",
        ")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "837165be89064b4697f48cea3ef2c76d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=150.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "id": "LEAkVJWil4nG",
        "outputId": "561c247d-93f3-45ac-835b-3acc9b572d2c"
      },
      "source": [
        "plot_regret(metrics['regret'], {'algorithm': 'LinTS'})"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBsLy4I8l6bh"
      },
      "source": [
        ""
      ],
      "execution_count": 21,
      "outputs": []
    }
  ]
}